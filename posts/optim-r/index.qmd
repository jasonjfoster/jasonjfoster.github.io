---
title: "Optimization"
author: "[Jason Foster](mailto:jason.j.foster@gmail.com)"
date: last-modified
categories:
  - analysis
  - finance
  - r
---

```{r, echo = FALSE, message = FALSE}
source("../plot/theme_jjf.R")
```

```{r, message = FALSE}
library(quantmod)
library(roll)
library(data.table)
```

```{r, echo = FALSE}
options("getSymbols.warning4.0" = FALSE)
```

```{r}
factors_r <- c("SP500", "DTWEXAFEGS") # "SP500" does not contain dividends; note: "DTWEXM" discontinued as of Jan 2020
factors_d <- c("DGS10", "BAMLH0A0HYM2")
factors <- c(factors_r, factors_d)
width <- 252
scale <- list("periods" = 252, "overlap" = 5)
```

```{r, echo = FALSE}
palette <- c("black", palette_jjf(length(factors)))
names(palette) <- c("Overall", factors)
```

```{r, results = "hide"}
getSymbols(factors, src = "FRED")
levels_xts <- do.call(merge, c(lapply(factors, function(i) get(i)), all = TRUE))
```

```{r}
returns_xts <- do.call(merge, lapply(factors, function(i) {
    if (i %in% factors_r) {
        diff(log((levels_xts[ , i])))
    } else if (i %in% factors_d) {
        -diff(levels_xts[ , i]) / 100
    }    
}))
overlap_xts <- roll_mean(returns_xts, scale[["overlap"]], min_obs = 1, na_restore = TRUE)
```

```{r, message = FALSE}
library(CVXR)
```

```{r}
tickers <- "BAICX" # fund inception date is "2011-11-28" 
invisible(getSymbols(tickers, src = "tiingo", api.key = Sys.getenv("TIINGO_API_KEY"), adjust = TRUE))
prices_xts <- do.call(merge, c(lapply(tickers, function(i) Cl(get(i))), all = TRUE))
colnames(prices_xts) <- tickers
index(prices_xts) <- as.Date(index(prices_xts))
```

```{r}
returns_xts <- merge(returns_xts, diff(log(prices_xts)))
overlap_xts <- merge(overlap_xts, roll_mean(returns_xts[ , tickers], scale[["overlap"]], min_obs = 1))
```

```{r}
# weights <- 0.9 ^ ((width - 1):0)
weights <- rep(1, width)
```

```{r}
overlap_xts <- na.omit(overlap_xts)
overlap_x_xts <- tail(overlap_xts[ , factors], width) # same dimension as `weights`
overlap_y_xts <- tail(overlap_xts[ , tickers], width)
```

# Random weights

Need to generate uniformly distributed weights $\mathbf{w}=(w_{1},w_{2},\ldots,w_{N})$ such that $\sum_{j=1}^{N}w_{i}=1$ and $w_{i}\geq0$:

-   **Approach 1**: tempting to use $w_{i}=\frac{u_{i}}{\sum_{j=1}^{N}u_{i}}$ where $u_{i}\sim U(0,1)$ but the distribution of $\mathbf{w}$ is not uniform

-   **Approach 2**: instead, generate $\text{Exp}(1)$ and then normalize

Can also scale random weights by $M$, e.g. if sum of weights must be 10% then multiply weights by 10%.

```{r}
rand_weights1 <- function(n_sim, n_assets) {
    
    rand_exp <- matrix(runif(n_sim * n_assets), nrow = n_sim, ncol = n_assets)
    result <- rand_exp / rowSums(rand_exp)
    
    return(result)
    
}
```

```{r}
n_assets <- 3
n_sim <- 10000
```

```{r}
approach1 <- rand_weights1(n_sim, n_assets)
```

```{r, echo = FALSE, fig.width = 4, fig.height = 4}
plot_pairs(as.data.table(approach1), title = "Weight (%)")
```

**Approach 2(a)**: uniform sample from the simplex (<http://mathoverflow.net/a/76258>) and then normalize

-   If $u\sim U(0,1)$ then $-\ln(u)$ is an $\text{Exp}(1)$ distribution

This is also known as generating a random vector from the symmetric Dirichlet distribution.

```{r}
rand_weights2a <- function(n_sim, n_assets, lmbda) {
    
    # use 'inverse transform sampling' method: https://en.wikipedia.org/wiki/Inverse_transform_sampling
    rand_exp <- matrix(-log(1 - runif(n_sim * n_assets)) / lmbda, nrow = n_sim, ncol = n_assets)
    result <- rand_exp / rowSums(rand_exp)
    
    return(result)
    
}
```

```{r}
lmbda <- 1
```

```{r}
approach2a <- rand_weights2a(n_sim, n_assets, lmbda)
```

```{r, echo = FALSE, fig.width = 4, fig.height = 4}
plot_pairs(as.data.table(approach2a), title = "Weight (%)")
```

**Approach 2(b)**: directly generate $\text{Exp}(1)$ and then normalize

```{r}
rand_weights2b <- function(n_sim, n_assets) {
    
    rand_exp <- matrix(rexp(n_sim * n_assets), nrow = n_sim, ncol = n_assets)
    result <- rand_exp / rowSums(rand_exp)
    
    return(result)
    
}
```

```{r}
approach2b <- rand_weights2b(n_sim, n_assets)
```

```{r, echo = FALSE, fig.width = 4, fig.height = 4}
plot_pairs(as.data.table(approach2b), title = "Weight (%)")
```

## Random turnover

How to generate random weights between lower bound $a$ and upper bound $b$ that sum to zero?

-   **Approach 1**: tempting to multiply random weights by $M$ and then subtract by $\frac{M}{N}$ but the distribution is not between $a$ and $b$

-   **Approach 2**: instead, use an iterative approach for random turnover:

    1.  Generate $N-1$ uniformly distributed weights between $a$ and $b$
    2.  For $u_{N}$ compute sum of values and subtract from $M$
    3.  If $u_{N}$ is between $a$ and $b$, then keep; otherwise, discard

Then add random turnover to previous period's random weights.

```{r}
rand_turnover1 <- function(n_sim, n_assets, lower, upper, target) {
    
    rng <- upper - lower
    
    result <- rand_weights2b(n_sim, n_assets) * rng
    result <- result - rng / n_assets
    
    return(result)
    
}
```

```{r}
lower <- -0.05
upper <- 0.05
target <- 0
```

```{r}
approach1 <- rand_turnover1(n_sim, n_assets, lower, upper, target)
```

```{r, echo = FALSE, fig.width = 4, fig.height = 4}
plot_pairs(as.data.table(approach1), title = "Weight (%)")
```

```{r}
rand_iterative <- function(n_assets, lower, upper, target) {
    
    result <- runif(n_assets - 1, min = lower, max = upper)
    temp <- target - sum(result)
    
    while (!((temp <= upper) && (temp >= lower))) {
        
        result <- runif(n_assets - 1, min = lower, max = upper)
        temp <- target - sum(result)
        
    }
    
    result <- append(result, temp)
    
    return(result)
    
}
```

```{r}
rand_turnover2 <- function(n_sim, n_assets, lower, upper, target) {
  
    result_ls <- list()
    
    for (i in 1:n_sim) {
        
        result_sim <- rand_iterative(n_assets, lower, upper, target)
        result_ls <- append(result_ls, list(result_sim))
        
    }
    
    result <- do.call(rbind, result_ls)
    
    return(result)
    
}
```

```{r}
approach2 <- rand_turnover2(n_sim, n_assets, lower, upper, target)
```

```{r, echo = FALSE, fig.width = 4, fig.height = 4}
plot_pairs(as.data.table(approach2), title = "Weight (%)")
```

# Mean-variance

```{r}
geometric_mean <- function(x, scale) {
    
    result <- prod(1 + x) ^ (scale / length(x)) - 1
    
    return(result)
    
}
```

```{r}
returns_x_xts <- na.omit(returns_xts)[ , factors] # extended history # REMOVE LATER
mu <- apply(returns_x_xts, 2, geometric_mean, scale = scale[["periods"]])
sigma <- cov(overlap_x_xts) * scale[["periods"]] * scale[["overlap"]]
```

## Maximize mean

$$
\begin{aligned}
\begin{array}{rrcl}
\displaystyle\max_{x}&\mu^{T}\mathbf{w}\\
\textrm{s.t.}&\mathbf{w}^T\Sigma\mathbf{w}&\leq&\sigma^{2}\\
&e^T\mathbf{w}&=&1
\end{array}
\end{aligned}
$$

```{r}
target <- 0.06
```

-   <https://palomar.home.ece.ust.hk/MAFS6010R_lectures/slides_robust_portfolio.html>

```{r}
max_pnl_optim <- function(mu, sigma, target) {
    
    params <- Variable(length(mu))
    
    cons <- list(params >= 0, sum(params) == 1,
                 quad_form(params, sigma) <= target ^ 2)
    
    obj <- Maximize(t(params) %*% mu)
        
    result <- solve(Problem(obj, cons))$getValue(params)
    
    return(result)

}
```

```{r}
params1 <- max_pnl_optim(mu, sigma, target)
params1
```

```{r}
mu %*% params1
```

```{r}
sqrt(t(params1) %*% sigma %*% params1)
```

## Minimize variance

$$
\begin{aligned}
\begin{array}{rrcl}
\displaystyle\min_{x}&\mathbf{w}^T\Sigma\mathbf{w}\\
\textrm{s.t.}&\mu^{T}\mathbf{w}&\geq&M\\
&e^T\mathbf{w}&=&1
\end{array}
\end{aligned}
$$

```{r}
target <- 0.03
```

```{r}
min_risk_optim <- function(mu, sigma, target) {
    
    params <- Variable(length(mu))
    
    cons <- list(params >= 0, sum(params) == 1,
                 sum(mu * params) >= target)
    
    obj <- Minimize(quad_form(params, sigma))
        
    result <- solve(Problem(obj, cons))$getValue(params)
    
    return(result)

}
```

```{r}
params2 <- min_risk_optim(mu, sigma, target)
params2
```

```{r}
mu %*% params2
```

```{r}
sqrt(t(params2) %*% sigma %*% params2)
```

## Maximize utility

$$
\begin{aligned}
\begin{array}{rrcl}
\displaystyle\max_{x}&\mu^{T}\mathbf{w}-\frac{1}{2}\delta(\mathbf{w}^T\Sigma\mathbf{w})\\
\textrm{s.t.}&e^T\mathbf{w}&=&1
\end{array}
\end{aligned}
$$

```{r}
ir <- 0.5
target <- ir / 0.06 # ir / std (see Black-Litterman)
```

```{r}
max_ratio_optim <- function(mu, sigma, target) {
    
    params <- Variable(length(mu))
    
    cons <- list(params >= 0, sum(params) == 1)
    
    obj <- Maximize(t(mu) %*% params - 0.5 * target * quad_form(params, sigma))
        
    result <- solve(Problem(obj, cons))$getValue(params)
    
    return(result)

}
```

```{r}
params3 <- max_ratio_optim(mu, sigma, target)
params3
```

```{r}
mu %*% params3
```

```{r}
sqrt(t(params3) %*% sigma %*% params3)
```

## Minimize residual sum of squares

```{r}
data.frame("max_pnl" = params1,
           "min_risk" = params2,
           "max_ratio" = params3)
```
