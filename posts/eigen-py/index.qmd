---
title: "Eigen"
author: "[Jason Foster](mailto:jason.j.foster@gmail.com)"
date: last-modified
categories:
  - analysis
  - finance
  - python
---

```{python, echo = FALSE}
# closed: https://github.com/rstudio/rstudio/issues/5945
# closed: https://github.com/rstudio/reticulate/issues/808
# closed: https://github.com/rstudio/reticulate/issues/847
# open: "run all chunks"
```

```{r, echo = FALSE, message = FALSE}
library(reticulate)
library(data.table)
source("../plot/theme_jjf.R")
```

```{python}
import pandas as pd
import numpy as np
import statsmodels.api as sm
import pandas_datareader as pdr
from scipy.stats import norm, chi2
```

```{python}
factors_r = ["SP500", "DTWEXAFEGS"] # "SP500" does not contain dividends; note: "DTWEXM" discontinued as of Jan 2020
factors_d = ["DGS10", "BAMLH0A0HYM2"]
factors = factors_r + factors_d
width = 252
scale = {"periods": 252, "overlap": 5}
```

```{r, echo = FALSE}
palette <- c("black", palette_jjf(length(py$factors)))
names(palette) <- c("Overall", py$factors)
```

-   <https://pandas-datareader.readthedocs.io/en/latest/remote_data.html>

```{python}
levels_df = pdr.get_data_fred(factors, start = "1900-01-01")
```

```{python}
returns_df = levels_df.apply(lambda x: np.log(x).diff() if x.name in factors_r else -x.diff() / 100)
overlap_df = returns_df.rolling(scale["overlap"], min_periods = 1).mean()
returns_df = pd.concat([returns_df, overlap_df], keys = ["returns", "overlap"], axis = 1)
```

```{python}
overlap_df = returns_df.dropna()["overlap"]
```

# Decomposition

Underlying returns are structural bets that can be analyzed through dimension reduction techniques such as principal components analysis (PCA). Most empirical studies apply PCA to a covariance matrix (*note: for multi-asset portfolios, use the correlation matrix because asset-class variances are on different scales*) of equity returns (yield changes) and find that movements in the equity markets (yield curve) can be explained by a subset of principal components. For example, the yield curve can be decomposed in terms of shift, twist, and butterfly, respectively.

$$
\begin{aligned}
\boldsymbol{\Sigma}&=\lambda_{1}\mathbf{v}_{1}\mathbf{v}_{1}^\mathrm{T}+\lambda_{2}\mathbf{v}_{2}\mathbf{v}_{2}^\mathrm{T}+\cdots+\lambda_{k}\mathbf{v}_{k}\mathbf{v}_{k}^\mathrm{T}\\
&=V\Lambda V^{\mathrm{T}}
\end{aligned}
$$

-   <https://www.r-bloggers.com/fixing-non-positive-definite-correlation-matrices-using-r-2/>

```{python}
def eigen_decomp(x, comps):
    
    L, V = np.linalg.eig(np.cov(x.T, ddof = 1))
    idx = L.argsort()[::-1]
    L = L[idx]
    V = V[:, idx]
        
    L = L[:comps]
    V = V[:, :comps]
    
    result = np.dot(V, np.multiply(L, V.T))
    
    return result
```

```{python}
comps = 1
```

```{python}
eigen_decomp(overlap_df, comps) * scale["periods"] * scale["overlap"]
```

```{python}
# np.cov(overlap_df.T) * scale["periods"] * scale["overlap"]
```

# Variance

We often look at the proportion of variance explained by the first $i$ principal components as an indication of how many components are needed.

$$
\begin{aligned}
\frac{\sum_{j=1}^{i}{\lambda_{j}}}{\sum_{j=1}^{k}{\lambda_{j}}}
\end{aligned}
$$

```{python}
def variance_explained(x):
    
    L, V = np.linalg.eig(np.cov(x.T, ddof = 1))   
    idx = L.argsort()[::-1]
    L = L[idx]
    
    result = L.cumsum() / L.sum()
    
    return result
```

```{python}
variance_explained(overlap_df)
```

# Similarity

Also, a challenge of rolling PCA is to try to match the eigenvectors: may need to change the sign and order.

$$
\begin{aligned}
\text{similarity}=\frac{\mathbf{A}\cdot\mathbf{B}}{\|\mathbf{A}\|\|\mathbf{B}\|}
\end{aligned}
$$

```{python}
def eigen(x):
  
    L, V = np.linalg.eig(np.cov(x.T, ddof = 1))
    idx = L.argsort()[::-1]
    L = L[idx]
    V = V[:, idx]
    
    result = {
        "values": L,
        "vectors": V
    }
    
    return result
```

```{python}
def roll_eigen1(x, width, comp):
    
    n_rows = len(x)
    result_ls = []
    
    for i in range(width - 1, n_rows):
        
        idx = range(max(i - width + 1, 0), i + 1)
        evec = eigen(x.iloc[idx])["vectors"][:, comp - 1]
        result_ls.append(evec)
    
    result_df = pd.DataFrame(result_ls, index = x.index[(width - 1):],
                             columns = x.columns)
    
    return result_df  
```

```{python}
comp = 1
```

```{python}
raw_df = roll_eigen1(overlap_df, width, comp)
```

```{r, echo = FALSE, fig.width = 6, fig.height = 3}
raw_mlt <- melt(as.data.table(py$raw_df, keep.rownames = "index"), id.vars = "index")
raw_mlt[ , index := as.Date(index)]
raw_plt <- plot_ts(raw_mlt, title = "Eigenvector 1Y")
print(raw_plt)
```

-   <https://quant.stackexchange.com/a/3095>
-   <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4400158>

```{python}
def roll_eigen2(x, width, comp):
    
    n_rows = len(x)
    result_ls = []
    
    for i in range(width - 1, n_rows):
        
        idx = range(max(i - width + 1, 0), i + 1)
        evecs = eigen(x.iloc[idx])["vectors"]
        
        if i > width - 1:
            
            similarity = np.dot(evecs.T, result_ls[-1])
            order = np.argmax(np.abs(similarity))
            evec = np.multiply(np.sign(similarity[order]), evecs[:, order])
            
            result_ls.append(evec)
            
        else:
            result_ls.append(evecs[:, comp - 1])
    
    result_df = pd.DataFrame(result_ls, index = x.index[(width - 1):],
                             columns = x.columns)
    
    return result_df
```

```{python}
clean_df = roll_eigen2(overlap_df, width, comp)
```

```{r, echo = FALSE, fig.width = 6, fig.height = 3}
clean_mlt <- melt(as.data.table(py$clean_df, keep.rownames = "index"), id.vars = "index")
clean_mlt[ , index := as.Date(index)]
clean_plt <- plot_ts(clean_mlt, title = "Eigenvector 1Y")
print(clean_plt)
```