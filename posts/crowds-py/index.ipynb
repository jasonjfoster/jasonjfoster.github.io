{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Crowds\"\n",
        "author: \"[Jason Foster](mailto:jason.j.foster@gmail.com)\"\n",
        "date: last-modified\n",
        "categories:\n",
        "  - analysis\n",
        "  - finance\n",
        "  - python\n",
        "draft: true\n",
        "---"
      ],
      "id": "029d1265"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "factors_r = [\"SP500\"] # \"SP500\" does not contain dividends\n",
        "factors_d = [\"DTB3\"]"
      ],
      "id": "4e57c6bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "exec(open(\"../helper-levels.py\").read())"
      ],
      "id": "3c0e6ef8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "width = 20 * 3"
      ],
      "id": "64eb8f34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parse web\n"
      ],
      "id": "e923475b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests"
      ],
      "id": "7b5af832",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Process:\n",
        "  \n",
        "  @staticmethod\n",
        "  def filter(filter):\n",
        "  \n",
        "    operator, operands = filter\n",
        "    \n",
        "    result = {\n",
        "      \"operator\": operator,\n",
        "      \"operands\": [\n",
        "          {\"operator\": operand[0], \"operands\": operand[1]} for operand in operands\n",
        "      ],\n",
        "    }\n",
        "    \n",
        "    return result\n",
        "    \n",
        "  # @staticmethod\n",
        "  # def url(params):\n",
        "  #   \n",
        "  #   result = \"?\" + \"&\".join(f\"{key}={value}\" for key, value in params.items())\n",
        "  #   \n",
        "  #   return result\n",
        "  \n",
        "  @staticmethod\n",
        "  def nest(df):\n",
        "    \n",
        "  \tdf = df.copy()\n",
        "  \t\n",
        "  \tfor col in df.columns:\n",
        "  \t  \n",
        "  \t\tif df[col].apply(lambda x: isinstance(x, list)).all():\n",
        "  \t\t\t\n",
        "  \t\t\tstatus_df = df[col].apply(lambda x: all(isinstance(i, dict) for i in x)).all()\n",
        "  \t\t\t\n",
        "  \t\t\tif status_df:\n",
        "  \t\t\t\t\n",
        "  \t\t\t\tcols = set()\n",
        "  \t\t\t\t\n",
        "  \t\t\t\tfor row in df[col]:\n",
        "  \t\t\t\t\tfor item in row:\n",
        "  \t\t\t\t\t  \n",
        "  \t\t\t\t\t\tflattened_item = pd.json_normalize(item, sep = \".\", max_level = None)\n",
        "  \t\t\t\t\t\tcols.update(flattened_item.columns)\n",
        "  \t\t\t\t\n",
        "  \t\t\t\trow_na = {key: None for key in cols}\n",
        "  \t\t\t\t\n",
        "  \t\t\t\tresult_ls = []\n",
        "  \t\t\t\t\n",
        "  \t\t\t\tfor row in df[col]:\n",
        "  \t\t\t\t\t\n",
        "  \t\t\t\t\tif not row:\n",
        "  \t\t\t\t\t\tresult_ls.append(row_na)\n",
        "  \t\t\t\t\telse:\n",
        "  \t\t\t\t\t  \n",
        "  \t\t\t\t\t\tflattened_row = pd.json_normalize(row[0]).to_dict(orient = \"records\")[0]\n",
        "  \t\t\t\t\t\tresult = {key: flattened_row.get(key, None) for key in cols}\n",
        "  \t\t\t\t\t\t\n",
        "  \t\t\t\t\t\tcols_na = cols - result.keys()\n",
        "  \t\t\t\t\t\t\n",
        "  \t\t\t\t\t\tfor col_na in cols_na:\n",
        "  \t\t\t\t\t\t\tresult[col_na] = None\n",
        "  \t\t\t\t\t\t\n",
        "  \t\t\t\t\t\tresult_ls.append(result)\n",
        "  \t\t\t\t\n",
        "  \t\t\t\tresult_df = pd.DataFrame(result_ls)\n",
        "  \t\t\t\tdf = pd.concat([df.reset_index(drop = True), result_df], axis = 1)\n",
        "  \t\t\t\t\n",
        "  \t\t\t\tdf.drop(columns = [col], inplace=True)\n",
        "  \t\t\t\t\n",
        "  \t\t\telse:\n",
        "  \t\t\t\tdf[col] = None\n",
        "  \t\n",
        "  \treturn df"
      ],
      "id": "1a62e333",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Query:\n",
        "  \n",
        "  @staticmethod\n",
        "  def create(filters = [(\"or\", [(\"eq\", [\"region\", \"us\"])])],\n",
        "             top_operator = \"and\"):\n",
        "    \n",
        "    result = {\n",
        "      \"operator\": top_operator,\n",
        "      \"operands\": [Process.filter(filter) for filter in filters],\n",
        "    }\n",
        "\n",
        "    return result"
      ],
      "id": "5fac7615",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Payload:\n",
        "  \n",
        "  @staticmethod\n",
        "  def create(quote_type = \"equity\", query = Query.create(),\n",
        "             size = 25, offset = 0,\n",
        "             sort_field = None, sort_type = None,\n",
        "             top_operator = \"and\"):\n",
        "    \n",
        "    result = {\n",
        "      \"includeFields\": None,  # unable to modify the result\n",
        "      \"offset\": offset,\n",
        "      \"query\": query,\n",
        "      \"quoteType\": quote_type,\n",
        "      \"size\": size,\n",
        "      \"sortField\": sort_field,\n",
        "      \"sortType\": sort_type,\n",
        "      \"topOperator\": top_operator,\n",
        "    }\n",
        "    \n",
        "    return result"
      ],
      "id": "b594fda7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Session:\n",
        "  \n",
        "  @staticmethod\n",
        "  def get():\n",
        "    \n",
        "    session = requests.Session()\n",
        "    \n",
        "    api_url = \"https://query1.finance.yahoo.com/v1/test/getcrumb\"\n",
        "    \n",
        "    headers = {\n",
        "      \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
        "      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n",
        "    }\n",
        "    \n",
        "    session.headers.update(headers)\n",
        "  \n",
        "    response = session.get(api_url)\n",
        "    \n",
        "    crumb = response.text.strip()\n",
        "    cookies = session.cookies.get_dict()\n",
        "  \n",
        "    result = {\n",
        "      \"handle\": session,\n",
        "      \"crumb\": crumb,\n",
        "      \"cookies\": cookies\n",
        "    }\n",
        "    \n",
        "    return result"
      ],
      "id": "777fe762",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Screen:\n",
        "  \n",
        "  @staticmethod\n",
        "  def get(payload = Payload.create()):\n",
        "  \n",
        "    session = Session.get()\n",
        "    crumb = session[\"crumb\"]\n",
        "    cookies = session[\"cookies\"]\n",
        "    handle = session[\"handle\"]\n",
        "  \n",
        "    params = {\n",
        "      \"crumb\": crumb,\n",
        "      \"lang\": \"en-US\",\n",
        "      \"region\": \"US\",\n",
        "      \"formatted\": \"true\",\n",
        "      \"corsDomain\": \"finance.yahoo.com\",\n",
        "    }\n",
        "  \n",
        "    api_url = \"https://query1.finance.yahoo.com/v1/finance/screener\" # + Process.url(params)\n",
        "  \n",
        "    headers = {\n",
        "      # \"Content-Type\": \"application/json\",\n",
        "      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n",
        "    }\n",
        "  \n",
        "    max_size = 250\n",
        "    size = payload[\"size\"]\n",
        "    offset = payload[\"offset\"]\n",
        "    \n",
        "    result_cols = set()\n",
        "    result_ls = []\n",
        "\n",
        "    while size > 0:\n",
        "  \n",
        "      chunk_size = min(size, max_size)\n",
        "      payload[\"size\"] = chunk_size\n",
        "      payload[\"offst\"] = offset\n",
        "  \n",
        "      for key, value in cookies.items():\n",
        "        handle.cookies.set(key, value)\n",
        "  \n",
        "      response = handle.post(api_url, params = params, json = payload, headers = headers)\n",
        "  \n",
        "      result = response.json()\n",
        "      result_df = result[\"finance\"][\"result\"][0][\"quotes\"]\n",
        "  \n",
        "      if (result_df is not None):\n",
        "        \n",
        "        result_df = pd.json_normalize(result_df)\n",
        "        result_df = Process.nest(result_df)\n",
        "        \n",
        "        result_ls.append(result_df)\n",
        "        result_cols.update(result_df.columns)\n",
        "  \n",
        "        size -= chunk_size\n",
        "        offset += chunk_size\n",
        "  \n",
        "      else:\n",
        "        size = 0\n",
        "        \n",
        "    result_cols = list(result_cols)\n",
        "    \n",
        "    for i in range(len(result_ls)):\n",
        "      \n",
        "      x = result_ls[i]\n",
        "      cols_na = set(result_cols) - set(x.columns)\n",
        "      \n",
        "      for j in cols_na:\n",
        "        x[j] = None\n",
        "        \n",
        "      result_ls[i] = x[result_cols]\n",
        "    \n",
        "    result = pd.concat(result_ls, ignore_index = True)\n",
        "    \n",
        "    return result"
      ],
      "id": "58d7652e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimization\n"
      ],
      "id": "f82960ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "import cvxpy as cp"
      ],
      "id": "5e86b7f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def min_rss_optim(x, y):\n",
        "    \n",
        "    w = cp.Variable(x.shape[1])\n",
        "    \n",
        "    objective = cp.Minimize(cp.sum_squares(y - x @ w))\n",
        "    \n",
        "    constraints = [cp.sum(w) == 1, w >= 0, w <= 1]\n",
        "    \n",
        "    problem = cp.Problem(objective, constraints)\n",
        "    problem.solve()\n",
        "    \n",
        "    return w.value"
      ],
      "id": "b39b2af7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "filters = [(\"or\", [(\"eq\", [\"categoryname\", \"Tactical Allocation\"])])]\n",
        "query = Query.create(filters)\n",
        "payload = Payload.create(quote_type = \"mutualfund\", query = query, size = 250,\n",
        "                         sort_field = \"fundnetassets\")\n",
        "screen = Screen.get(payload)"
      ],
      "id": "16a9fefb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sorted_df = screen.sort_values(by = [\"netAssets.raw\", \"firstTradeDateMilliseconds\"])\n",
        "tickers = sorted_df.loc[~sorted_df[\"netAssets.raw\"].duplicated(), \"symbol\"].tolist()"
      ],
      "id": "0de33959",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# allocations = [\"AOK\", \"AOM\", \"AOR\", \"AOA\"]\n",
        "# tickers = tickers + allocations"
      ],
      "id": "16bfb16e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "exec(open(\"../helper-prices.py\").read())"
      ],
      "id": "31e5c4ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "overlap_df = returns_df.rolling(scale[\"overlap\"],min_periods = 1).mean()\n",
        "\n",
        "# overlap_df = overlap_df.dropna()\n",
        "overlap_x_df = overlap_df[factors]\n",
        "overlap_y_df = overlap_df[tickers]\n",
        "# overlap_z_df = overlap_df[allocations]"
      ],
      "id": "e9def302",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def pnl(x):\n",
        "    return np.nanprod(1 + x) - 1"
      ],
      "id": "f00141c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "performance_df = returns_df.rolling(width, min_periods = 1).apply(pnl, raw = False)"
      ],
      "id": "d2a98875",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_rows = overlap_df.shape[0]\n",
        "result_ls = []\n",
        "index_ls = []\n",
        "\n",
        "# for i in range(width - 1, n_rows):\n",
        "for i in range(n_rows - 1, n_rows):\n",
        "  \n",
        "  idx = range(max(i - width + 1, 0), i + 1)\n",
        "  x_subset = overlap_x_df.iloc[idx]\n",
        "  y_subset = overlap_y_df.iloc[idx]\n",
        "  params_ls = []\n",
        "  tickers_ls = []\n",
        "  performance_ls = []\n",
        "  \n",
        "  # for j in [ticker for ticker in tickers if ticker not in allocations]:\n",
        "  for j in tickers:\n",
        "    \n",
        "    idx = ~x_subset.isna().any(axis = 1) & ~y_subset[j].isna()\n",
        "    x_complete = x_subset.loc[idx]\n",
        "    y_complete = y_subset.loc[idx, j]\n",
        "    \n",
        "    if (x_complete.shape[0] > 0) and (y_complete.size > 0):\n",
        "        \n",
        "      params = min_rss_optim(x_complete.values, y_complete.values)\n",
        "      params_ls.append(params)\n",
        "      \n",
        "      tickers_ls.append(j)\n",
        "      \n",
        "      performance_ls.append(performance_df[j].iloc[i])\n",
        "\n",
        "  if params_ls:\n",
        "    \n",
        "    result = pd.DataFrame(params_ls, index = tickers_ls)\n",
        "    result[\"performance\"] = performance_ls\n",
        "    \n",
        "    result_ls.append(result)\n",
        "    index_ls.append(overlap_x_df.index[i])"
      ],
      "id": "22f4c8da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# json.dump([x.to_dict() for x in result_ls], open(\"result_ls.json\", \"w\"))\n",
        "# json.dump([x.isoformat() for x in index_ls], open(\"index_ls.json\", \"w\"))"
      ],
      "id": "bc01c639",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Performance\n"
      ],
      "id": "a1318512"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# result_ls = [pd.DataFrame(x) for x in json.load(open(\"result_ls.json\", \"r\"))]\n",
        "# index_ls = [pd.Timestamp(x) for x in json.load(open(\"index_ls.json\", \"r\"))]"
      ],
      "id": "1abf6afc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def quantile_cut(x):\n",
        "  \n",
        "  result = pd.qcut(\n",
        "    -x,\n",
        "    q = [0, 0.25, 0.5, 0.75, 1],\n",
        "    labels = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
        "  )\n",
        "  \n",
        "  return result"
      ],
      "id": "51288189",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_rows = len(result_ls)\n",
        "score_ls = []\n",
        "\n",
        "for i in range(n_rows):\n",
        "  \n",
        "  score_df = pd.DataFrame(result_ls[i])\n",
        "  score_df.columns = factors + [\"performance\"]\n",
        "  \n",
        "  score_df[\"date\"] = index_ls[i]\n",
        "  score_df[\"quantile\"] = quantile_cut(score_df[\"performance\"])\n",
        "  \n",
        "  score = score_df.groupby([\"date\", \"quantile\"]).agg(\n",
        "    weight = (factors[0], \"mean\"),\n",
        "    performance = (\"performance\", \"mean\")\n",
        "  ).reset_index()\n",
        "  \n",
        "  overall = pd.DataFrame({\n",
        "    \"date\": [index_ls[i]],\n",
        "    \"quantile\": [\"Overall\"],\n",
        "    \"weight\": [score_df[factors[0]].mean()],\n",
        "    \"performance\": [score_df[\"performance\"].mean()]\n",
        "  })\n",
        "  \n",
        "  score = pd.concat([score, overall], ignore_index = True)\n",
        "  \n",
        "  score_ls.append(score)"
      ],
      "id": "92c3a9e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.concat(score_ls, ignore_index = True)"
      ],
      "id": "6a1a81c3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}