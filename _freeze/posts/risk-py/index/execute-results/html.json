{
  "hash": "a0167269b422b34541fc75da430fcd6c",
  "result": {
    "markdown": "---\ntitle: \"Risk\"\nauthor: \"[Jason Foster](mailto:jason.j.foster@gmail.com)\"\ndate: last-modified\ncategories:\n  - analysis\n  - finance\n  - python\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport pandas_datareader as pdr\nfrom scipy.stats import norm, chi2\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfactors_r = [\"SP500\", \"DTWEXAFEGS\"] # \"SP500\" does not contain dividends; note: \"DTWEXM\" discontinued as of Jan 2020\nfactors_d = [\"DGS10\", \"BAMLH0A0HYM2\"]\nfactors = factors_r + factors_d\nwidth = 252\nscale = {\"periods\": 252, \"overlap\": 5}\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n-   <https://pandas-datareader.readthedocs.io/en/latest/remote_data.html>\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlevels_df = pdr.get_data_fred(factors, start = \"1900-01-01\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nreturns_df = levels_df.apply(lambda x: np.log(x).diff() if x.name in factors_r else -x.diff() / 100)\noverlap_df = returns_df.rolling(scale[\"overlap\"], min_periods = 1).mean()\nreturns_df = pd.concat([returns_df, overlap_df], keys = [\"returns\", \"overlap\"], axis = 1)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\n```\n:::\n\n\n-   Open: <https://github.com/pydata/pandas-datareader/issues/965>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntickers = [\"BAICX\"] # fund inception date is \"2011-11-28\"\nprices_df = pdr.get_data_tiingo(tickers, start = \"1900-01-01\", api_key = os.getenv(\"TIINGO_API_KEY\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nC:\\Users\\jason\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\pandas_datareader\\tiingo.py:234: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n  return pd.concat(dfs, self._concat_axis)\n```\n:::\n\n```{.python .cell-code}\nprices_df = prices_df.pivot_table(index = \"date\", columns = \"symbol\", values = \"adjClose\") \\\n    .tz_localize(None)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nreturns_cols = list(zip([\"returns\"], tickers))\noverlap_cols = list(zip([\"overlap\"], tickers))\nreturns_df[returns_cols] = np.log(prices_df).diff()\nreturns_df[overlap_cols] = returns_df[returns_cols].rolling(scale[\"overlap\"], min_periods = 1).mean()\nreturns_df.sort_index(axis = 1, inplace = True)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# weights = np.array([0.9 ** i for i in range(width - 1, -1, -1)]).reshape((width, 1))\nweights = np.array([1] * width).reshape((width, 1))\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\noverlap_df = returns_df.dropna()[\"overlap\"]\noverlap_x_df = returns_df.dropna()[\"overlap\"][factors][-width:]\noverlap_y_df = returns_df.dropna()[\"overlap\"][tickers][-width:]\n```\n:::\n\n\n# Regression analysis\n\n## Ordinary least squares\n\n\n::: {.cell}\n\n```{.python .cell-code}\nintercept = True\n```\n:::\n\n\n### Coefficients\n\n$$\n\\begin{aligned}\n\\hat{\\beta}=(X^\\mathrm{T}WX)^{-1}X^\\mathrm{T}Wy\n\\end{aligned}\n$$\n\n-   <https://faculty.washington.edu/ezivot/research/factormodellecture_handout.pdf>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_coef(x, y, weights, intercept):\n    \n    if (intercept): x = sm.add_constant(x)\n        \n    result = np.dot(np.linalg.inv(np.dot(x.T, np.multiply(weights, x))),\n                    np.dot(x.T, np.multiply(weights, y)))\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_coef(overlap_x_df, overlap_y_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 3.20013712e-06,  2.22039573e-01, -1.29651349e-01,  2.58862115e+00,\n        1.59982881e+00])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nif (intercept): overlap_x_df = sm.add_constant(overlap_x_df)\n    \nfit = sm.WLS(overlap_y_df, overlap_x_df, weights = weights).fit()\n\nif (intercept): overlap_x_df = overlap_x_df.iloc[:, 1:]\n\nnp.array(fit.params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 3.20013712e-06,  2.22039573e-01, -1.29651349e-01,  2.58862115e+00,\n        1.59982881e+00])\n```\n:::\n:::\n\n\n### R-squared\n\n$$\n\\begin{aligned}\nR^{2}=\\frac{\\hat{\\beta}^\\mathrm{T}(X^\\mathrm{T}WX)\\hat{\\beta}}{y^\\mathrm{T}Wy}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_rsq(x, y, weights, intercept):\n            \n    coef = np.matrix(lm_coef(x, y, weights, intercept))\n    \n    if (intercept):\n        \n        x = sm.add_constant(x)\n        x = x - np.average(x, axis = 0, weights = weights.reshape(-1))\n        y = y - np.average(y, axis = 0, weights = weights.reshape(-1))\n        \n    result = np.dot(coef, np.dot(np.dot(x.T, np.multiply(weights, x)), coef.T)) / \\\n        np.dot(y.T, np.multiply(weights, y))\n    \n    return result.item()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_rsq(overlap_x_df, overlap_y_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.8510258994398467\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfit.rsquared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.8510258994398463\n```\n:::\n:::\n\n\n### Standard errors\n\n$$\n\\begin{aligned}\n\\sigma_{\\hat{\\beta}}^{2}&=\\sigma_{\\varepsilon}^{2}(X^\\mathrm{T}WX)^{-1}\\\\\n&=\\frac{(1-R^{2})}{n-p}(X^\\mathrm{T}WX)^{-1}\\\\\n&=\\frac{SSE}{df_{E}}(X^\\mathrm{T}WX)^{-1}\\\\\n\\sigma_{\\hat{\\alpha}}^{2}&=\\sigma_{\\varepsilon}^{2}\\left(\\frac{1}{n}+\\mu^\\mathrm{T}(X^\\mathrm{T}WX)^{-1}\\mu\\right)\n\\end{aligned}\n$$\n\n-   <http://people.duke.edu/~rnau/mathreg.htm>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_se(x, y, weights, intercept):\n    \n    n_rows = x.shape[0]\n    n_cols = x.shape[1]\n    \n    rsq = lm_rsq(x, y, weights, intercept)\n    \n    if (intercept):\n        \n        x = sm.add_constant(x)\n        y = y - np.average(y, axis = 0, weights = weights.reshape(-1))\n        \n        df_resid = n_rows - n_cols - 1 \n        \n    else:\n        df_resid = n_rows - n_cols        \n    \n    var_y = np.dot(y.T, np.multiply(weights, y))\n    var_resid = (1 - rsq) * var_y / df_resid\n    \n    result = np.sqrt(var_resid * np.linalg.inv(np.dot(x.T, np.multiply(weights, x))).diagonal())\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_se(overlap_x_df, overlap_y_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([5.25910257e-05, 1.89831347e-02, 3.59440066e-02, 1.83078139e-01,\n       1.58116820e-01])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.array(fit.bse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([5.25910257e-05, 1.89831347e-02, 3.59440066e-02, 1.83078139e-01,\n       1.58116820e-01])\n```\n:::\n:::\n\n\n## Principal component regression\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ncomps = 1\n```\n:::\n\n\n### Coefficients\n\n$$\n\\begin{aligned}\nW_{k}&=\\mathbf{X}V_{k}=[\\mathbf{X}\\mathbf{v}_{1},\\ldots,\\mathbf{X}\\mathbf{v}_{k}]\\\\\n{\\widehat{\\gamma}}_{k}&=\\left(W_{k}^\\mathrm{T}W_{k}\\right)^{-1}W_{k}^\\mathrm{T}\\mathbf{Y}\\\\\n{\\widehat{\\boldsymbol{\\beta}}}_{k}&=V_{k}{\\widehat{\\gamma}}_{k}\n\\end{aligned}\n$$\n\n-   <https://en.wikipedia.org/wiki/Principal_component_regression>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pcr_coef(x, y, comps):\n    \n    x = x - np.average(x, axis = 0)\n    L, V = np.linalg.eig(np.cov(x.T, ddof = 1))\n    idx = L.argsort()[::-1]\n    V = V[:, idx]\n    \n    W = np.dot(x, V)\n    gamma = np.dot(np.dot(np.linalg.inv(np.dot(W.T, W)), W.T), y)\n    \n    result = np.dot(V[:, :comps], gamma[:comps])\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nscale_x_df = (overlap_x_df - np.average(overlap_x_df, axis = 0)) \\\n    / np.std(overlap_x_df, axis = 0, ddof = 1)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_coef(scale_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 0.00081497, -0.00072018,  0.00056396,  0.00056363])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_coef(overlap_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 0.40829748, -0.09352349,  0.01108694,  0.0280529 ])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npca = PCA(n_components = len(factors))\npca_x_df = pca.fit_transform(scale_x_df)\n\nfit = LinearRegression(fit_intercept = False).fit(pca_x_df, overlap_y_df)\n\ngamma = fit.coef_\nnp.dot(pca.components_.T[:, :comps], gamma.T[:comps]).ravel()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 0.00081497, -0.00072018,  0.00056396,  0.00056363])\n```\n:::\n:::\n\n\n### R-squared\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pcr_rsq(x, y, comps):\n    \n    coef = np.matrix(pcr_coef(x, y, comps))\n    \n    x = x - np.average(x, axis = 0)\n    y = y - np.average(y, axis = 0)\n    \n    result = np.dot(np.dot(coef, np.dot(x.T, x)), coef.T) / np.dot(y.T, y)\n    \n    return result.item()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_rsq(scale_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.8119209856908801\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_rsq(overlap_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.6770664200329685\n```\n:::\n:::\n\n\n### Standard errors\n\n$$\n\\begin{aligned}\n\\text{Var}({\\widehat{\\boldsymbol{\\beta}}}_{k})&=\\sigma^{2}V_{k}(W_{k}^\\mathrm{T}W_{k})^{-1}V_{k}^\\mathrm{T}\\\\\n&=\\sigma^{2}V_{k}\\text{diag}\\left(\\lambda_{1}^{-1},\\ldots,\\lambda_{k}^{-1}\\right)V_{k}^\\mathrm{T}\\\\\n&=\\sigma^{2}\\sum_{j=1}^{k}{\\frac{\\mathbf{v}_{j}\\mathbf{v}_{j}^\\mathrm{T}}{\\lambda_{j}}}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# unable to verify the result\ndef pcr_se(x, y, comps):\n    \n    n_rows = x.shape[0]\n    n_cols = x.shape[1]\n    \n    rsq = pcr_rsq(x, y, comps)\n    \n    y = y - np.average(y, axis = 0)\n    \n    df_resid = n_rows - n_cols - 1\n    \n    var_y = np.dot(y.T, y)   \n    var_resid = (1 - rsq) * var_y / df_resid\n    \n    # uses statsmodels for illustrative purposes\n    pca = sm.multivariate.PCA(x, standardize = False, demean = True)\n    L = pca.eigenvals[:comps]\n    V = pca.eigenvecs.iloc[:, :comps]\n    \n    result = np.sqrt(var_resid * np.dot(V, np.dot(np.diag(1 / L), V.T)).diagonal())\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_se(scale_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([2.49576774e-05, 2.20547907e-05, 1.72709143e-05, 1.72606128e-05])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_se(overlap_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.01794193, 0.00410973, 0.0004872 , 0.00123274])\n```\n:::\n:::\n\n\n## Partial least squares\n\n# Risk decomposition\n\n## Standalone risk\n\n$$\n\\begin{aligned}\n\\text{SAR}_{k}&=\\sqrt{w_{k}^{2}\\sigma_{k}^{2}}\\\\\n\\text{SAR}_{\\varepsilon}&=\\sqrt{(1-R^{2})\\sigma_{y}^{2}}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef cov_wt(x, weights, center):\n    \n    sum_w = sum(weights)\n    sumsq_w = sum(np.power(weights, 2))\n    \n    if (center):\n    \n        x = x - np.average(x, axis = 0, weights = weights.reshape(-1))\n    \n    result = np.dot(x.T, np.multiply(weights, x)) / (sum_w - sumsq_w / sum_w)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_sar(x, y, weights, intercept):\n    \n    coef = lm_coef(x, y, weights, intercept)\n    rsq = lm_rsq(x, y, weights, intercept)\n    \n    if (intercept): x = sm.add_constant(x)\n    \n    # sigma = np.cov(np.concatenate((x, y), axis = 1).T,\n    #                aweights = weights.reshape(-1))\n    sigma = cov_wt(np.concatenate((x, y), axis = 1), weights, intercept)\n    sar = np.multiply(np.power(coef, 2).T, sigma[:-1, :-1].diagonal())\n    sar_eps = (1 - rsq) * sigma[-1, -1]\n    \n    result = np.sqrt(np.concatenate((np.matrix(sigma[-1, -1]),\n                                     np.matrix(sar),\n                                     np.matrix(sar_eps)), axis = 1))\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_sar(overlap_x_df, overlap_y_df, weights, intercept) * np.sqrt(scale[\"periods\"]) * np.sqrt(scale[\"overlap\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.07518497, 0.        , 0.03192696, 0.00840318, 0.03211179,\n       0.02549763, 0.02901927])\n```\n:::\n:::\n\n\n## Risk contribution\n\n$$\n\\begin{aligned}\n\\text{MCR}&=w^\\mathrm{T}\\frac{\\partial\\sigma_{y}}{\\partial w}\\\\\n&=w^\\mathrm{T}\\frac{\\Sigma w}{\\sigma_{y}}\\\\\n\\text{MCR}_{\\varepsilon}&=\\sigma_{y}-\\sum_{k=1}^{n}\\text{MCR}_{k}\n\\end{aligned}\n$$\n\n-   <http://faculty.washington.edu/ezivot/research/factormodelrisklecture_handout.pdf>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_mcr(x, y, weights, intercept):\n    \n    coef = np.matrix(lm_coef(x, y, weights, intercept)).T\n    rsq = lm_rsq(x, y, weights, intercept)\n        \n    if (intercept): x = sm.add_constant(x)\n    \n#     sigma = np.cov(np.concatenate((x, y), axis = 1).T,\n#                    aweights = weights.reshape(-1))\n    sigma = cov_wt(np.concatenate((x, y), axis = 1), weights, intercept)\n    mcr = np.multiply(coef, np.dot(sigma[:-1, :-1], coef)) / np.sqrt(sigma[-1, -1])\n    mcr_eps = np.sqrt(sigma[-1, -1]) - sum(mcr)\n    \n    result = np.concatenate((np.sqrt(np.matrix(sigma[-1, -1])),\n                             np.matrix(mcr).T,\n                             np.matrix(mcr_eps)), axis = 1)\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_mcr(overlap_x_df, overlap_y_df, weights, intercept) * np.sqrt(scale[\"periods\"]) * np.sqrt(scale[\"overlap\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.07518497, 0.        , 0.02563386, 0.0047483 , 0.0185626 ,\n       0.01503959, 0.01120061])\n```\n:::\n:::\n\n\n# Scenario analysis\n\n## Implied shocks\n\n$$\n\\begin{aligned}\n\\hat{\\beta}&=(Z^\\mathrm{T}WZ)^{-1}Z^\\mathrm{T}WX\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef implied_shocks(shocks, x, z, weights):\n\n    beta = np.linalg.lstsq(np.multiply(weights, z), np.multiply(weights, x), rcond = None)[0]\n                     \n    result = np.dot(shocks, beta)\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nshocks = np.array([-0.1, 0.1])\noverlap_z_df = overlap_x_df.iloc[:, [0, 1]]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimplied_shocks(shocks, overlap_x_df, overlap_z_df, weights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([-0.1       ,  0.1       , -0.0102389 , -0.00353193])\n```\n:::\n:::\n\n\n## Stress P&L\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pnl_stress(shocks, x, y, z, weights, intercept):\n    \n    coef = lm_coef(x, y, weights, intercept)\n    \n    if (intercept): x = sm.add_constant(x)\n    \n    result = np.multiply(coef.T, implied_shocks(shocks, x, z, weights))\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npnl_stress(shocks, overlap_x_df, overlap_y_df, overlap_z_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([-2.17940780e-05, -2.22039573e-02, -1.29651349e-02, -2.65046303e-02,\n       -5.65047647e-03])\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}