{
  "hash": "e3d73ae9a3c8f4d74c9d30eb3fea0eb3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Risk\"\nauthor: \"[Jason Foster](mailto:jason.j.foster@gmail.com)\"\ndate: last-modified\ncategories:\n  - analysis\n  - finance\n  - python\n---\n\n::: {.cell}\n\n```{.python .cell-code}\nfactors_r = [\"SP500\", \"DTWEXAFEGS\"] # \"SP500\" does not contain dividends; note: \"DTWEXM\" discontinued as of Jan 2020\nfactors_d = [\"DGS10\", \"BAMLH0A0HYM2\"]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ntickers = [\"BAICX\"] # fund inception date is \"2011-11-28\"\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nintercept = True\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n# Regression analysis\n\n## Ordinary least squares\n\n### Coefficients\n\n$$\n\\begin{aligned}\n\\hat{\\beta}=(X^\\mathrm{T}WX)^{-1}X^\\mathrm{T}Wy\n\\end{aligned}\n$$\n\n-   <https://faculty.washington.edu/ezivot/research/factormodellecture_handout.pdf>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_coef(x, y, weights, intercept):\n    \n    if (intercept): x = sm.add_constant(x)\n        \n    result = np.dot(np.linalg.inv(np.dot(x.T, np.multiply(weights, x))),\n                    np.dot(x.T, np.multiply(weights, y)))\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_coef(overlap_x_df, overlap_y_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([-8.32784453e-05,  2.09261170e-01, -1.22516848e-01,  2.97264035e+00,\n        1.69710515e+00])\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nif (intercept): overlap_x_df = sm.add_constant(overlap_x_df)\n    \nfit = sm.WLS(overlap_y_df, overlap_x_df, weights = weights).fit()\n\nif (intercept): overlap_x_df = overlap_x_df.iloc[:, 1:]\n\nnp.array(fit.params)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([-8.32784453e-05,  2.09261170e-01, -1.22516848e-01,  2.97264035e+00,\n        1.69710515e+00])\n```\n\n\n:::\n:::\n\n\n### R-squared\n\n$$\n\\begin{aligned}\nR^{2}=\\frac{\\hat{\\beta}^\\mathrm{T}(X^\\mathrm{T}WX)\\hat{\\beta}}{y^\\mathrm{T}Wy}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_rsq(x, y, weights, intercept):\n            \n    coef = np.matrix(lm_coef(x, y, weights, intercept))\n    \n    if (intercept):\n        \n        x = sm.add_constant(x)\n        x = x - np.average(x, axis = 0, weights = weights.reshape(-1))\n        y = y - np.average(y, axis = 0, weights = weights.reshape(-1))\n        \n    result = np.dot(coef, np.dot(np.dot(x.T, np.multiply(weights, x)), coef.T)) / \\\n        np.dot(y.T, np.multiply(weights, y))\n    \n    return result.item()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_rsq(overlap_x_df, overlap_y_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.8196918819905119\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfit.rsquared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.8196918819905108\n```\n\n\n:::\n:::\n\n\n### Standard errors\n\n$$\n\\begin{aligned}\n\\sigma_{\\hat{\\beta}}^{2}&=\\sigma_{\\varepsilon}^{2}(X^\\mathrm{T}WX)^{-1}\\\\\n&=\\frac{(1-R^{2})}{n-p}(X^\\mathrm{T}WX)^{-1}\\\\\n&=\\frac{SSE}{df_{E}}(X^\\mathrm{T}WX)^{-1}\\\\\n\\sigma_{\\hat{\\alpha}}^{2}&=\\sigma_{\\varepsilon}^{2}\\left(\\frac{1}{n}+\\mu^\\mathrm{T}(X^\\mathrm{T}WX)^{-1}\\mu\\right)\n\\end{aligned}\n$$\n\n-   <http://people.duke.edu/~rnau/mathreg.htm>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_se(x, y, weights, intercept):\n    \n    n_rows = x.shape[0]\n    n_cols = x.shape[1]\n    \n    rsq = lm_rsq(x, y, weights, intercept)\n    \n    if (intercept):\n        \n        x = sm.add_constant(x)\n        y = y - np.average(y, axis = 0, weights = weights.reshape(-1))\n        \n        df_resid = n_rows - n_cols - 1 \n        \n    else:\n        df_resid = n_rows - n_cols        \n    \n    var_y = np.dot(y.T, np.multiply(weights, y))\n    var_resid = (1 - rsq) * var_y / df_resid\n    \n    result = np.sqrt(var_resid * np.linalg.inv(np.dot(x.T, np.multiply(weights, x))).diagonal())\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_se(overlap_x_df, overlap_y_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([5.48762928e-05, 2.15510071e-02, 3.88592800e-02, 2.09080066e-01,\n       1.76211642e-01])\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.array(fit.bse)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([5.48762928e-05, 2.15510071e-02, 3.88592800e-02, 2.09080066e-01,\n       1.76211642e-01])\n```\n\n\n:::\n:::\n\n\n## Principal component regression\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ncomps = 1\n```\n:::\n\n\n### Coefficients\n\n$$\n\\begin{aligned}\nW_{k}&=\\mathbf{X}V_{k}=[\\mathbf{X}\\mathbf{v}_{1},\\ldots,\\mathbf{X}\\mathbf{v}_{k}]\\\\\n{\\widehat{\\gamma}}_{k}&=\\left(W_{k}^\\mathrm{T}W_{k}\\right)^{-1}W_{k}^\\mathrm{T}\\mathbf{Y}\\\\\n{\\widehat{\\boldsymbol{\\beta}}}_{k}&=V_{k}{\\widehat{\\gamma}}_{k}\n\\end{aligned}\n$$\n\n-   <https://en.wikipedia.org/wiki/Principal_component_regression>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pcr_coef(x, y, comps):\n    \n    x = x - np.average(x, axis = 0)\n    L, V = np.linalg.eig(np.cov(x.T, ddof = 1))\n    idx = L.argsort()[::-1]\n    V = V[:, idx]\n    \n    W = np.dot(x, V)\n    gamma = np.dot(np.dot(np.linalg.inv(np.dot(W.T, W)), W.T), y)\n    \n    result = np.dot(V[:, :comps], gamma[:comps])\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nscale_x_df = (overlap_x_df - np.average(overlap_x_df, axis = 0)) \\\n    / np.std(overlap_x_df, axis = 0, ddof = 1)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_coef(scale_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([ 0.00079181, -0.00063733,  0.00040362,  0.00059184])\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_coef(overlap_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([ 0.40309609, -0.08186101,  0.00778702,  0.03104241])\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npca = PCA(n_components = len(factors))\npca_x_df = pca.fit_transform(scale_x_df)\n\nfit = LinearRegression(fit_intercept = False).fit(pca_x_df, overlap_y_df)\n\ngamma = fit.coef_\nnp.dot(pca.components_.T[:, :comps], gamma.T[:comps]).ravel()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([ 0.00079181, -0.00063733,  0.00040362,  0.00059184])\n```\n\n\n:::\n:::\n\n\n### R-squared\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pcr_rsq(x, y, comps):\n    \n    coef = np.matrix(pcr_coef(x, y, comps))\n    \n    x = x - np.average(x, axis = 0)\n    y = y - np.average(y, axis = 0)\n    \n    result = np.dot(np.dot(coef, np.dot(x.T, x)), coef.T) / np.dot(y.T, y)\n    \n    return result.item()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_rsq(scale_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.7624703514707666\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_rsq(overlap_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.6195998010886111\n```\n\n\n:::\n:::\n\n\n### Standard errors\n\n$$\n\\begin{aligned}\n\\text{Var}({\\widehat{\\boldsymbol{\\beta}}}_{k})&=\\sigma^{2}V_{k}(W_{k}^\\mathrm{T}W_{k})^{-1}V_{k}^\\mathrm{T}\\\\\n&=\\sigma^{2}V_{k}\\text{diag}\\left(\\lambda_{1}^{-1},\\ldots,\\lambda_{k}^{-1}\\right)V_{k}^\\mathrm{T}\\\\\n&=\\sigma^{2}\\sum_{j=1}^{k}{\\frac{\\mathbf{v}_{j}\\mathbf{v}_{j}^\\mathrm{T}}{\\lambda_{j}}}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# unable to verify the result\ndef pcr_se(x, y, comps):\n    \n    n_rows = x.shape[0]\n    n_cols = x.shape[1]\n    \n    rsq = pcr_rsq(x, y, comps)\n    \n    y = y - np.average(y, axis = 0)\n    \n    df_resid = n_rows - n_cols - 1\n    \n    var_y = np.dot(y.T, y)   \n    var_resid = (1 - rsq) * var_y / df_resid\n    \n    # uses statsmodels for illustrative purposes\n    pca = sm.multivariate.PCA(x, standardize = False, demean = True)\n    L = pca.eigenvals[:comps]\n    V = pca.eigenvecs.iloc[:, :comps]\n    \n    result = np.sqrt(var_resid * np.dot(V, np.dot(np.diag(1 / L), V.T)).diagonal())\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_se(scale_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([2.81203000e-05, 2.26341326e-05, 1.43340013e-05, 2.10186860e-05])\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npcr_se(overlap_x_df, overlap_y_df, comps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([0.0200967 , 0.00408125, 0.00038823, 0.00154765])\n```\n\n\n:::\n:::\n\n\n## Partial least squares\n\n# Risk decomposition\n\n## Standalone risk\n\n$$\n\\begin{aligned}\n\\text{SAR}_{k}&=\\sqrt{w_{k}^{2}\\sigma_{k}^{2}}\\\\\n\\text{SAR}_{\\varepsilon}&=\\sqrt{(1-R^{2})\\sigma_{y}^{2}}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef cov_wt(x, weights, center):\n    \n    sum_w = sum(weights)\n    sumsq_w = sum(np.power(weights, 2))\n    \n    if (center):\n    \n        x = x - np.average(x, axis = 0, weights = weights.reshape(-1))\n    \n    result = np.dot(x.T, np.multiply(weights, x)) / (sum_w - sumsq_w / sum_w)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_sar(x, y, weights, intercept):\n    \n    coef = lm_coef(x, y, weights, intercept)\n    rsq = lm_rsq(x, y, weights, intercept)\n    \n    if (intercept): x = sm.add_constant(x)\n    \n    # sigma = np.cov(np.concatenate((x, y), axis = 1).T,\n    #                aweights = weights.reshape(-1))\n    sigma = cov_wt(np.concatenate((x, y), axis = 1), weights, intercept)\n    sar = np.multiply(np.power(coef, 2).T, sigma[:-1, :-1].diagonal())\n    sar_eps = (1 - rsq) * sigma[-1, -1]\n    \n    result = np.sqrt(np.concatenate((np.matrix(sigma[-1, -1]),\n                                     np.matrix(sar),\n                                     np.matrix(sar_eps)), axis = 1))\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_sar(overlap_x_df, overlap_y_df, weights, intercept) * np.sqrt(scale[\"periods\"]) * np.sqrt(scale[\"overlap\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([0.06947363, 0.        , 0.02719046, 0.00718164, 0.03293295,\n       0.02617335, 0.02950038])\n```\n\n\n:::\n:::\n\n\n## Risk contribution\n\n$$\n\\begin{aligned}\n\\text{MCR}&=w^\\mathrm{T}\\frac{\\partial\\sigma_{y}}{\\partial w}\\\\\n&=w^\\mathrm{T}\\frac{\\Sigma w}{\\sigma_{y}}\\\\\n\\text{MCR}_{\\varepsilon}&=\\sigma_{y}-\\sum_{k=1}^{n}\\text{MCR}_{k}\n\\end{aligned}\n$$\n\n-   <https://bookdown.org/compfinezbook/introcompfinr/Portfolio-risk-reports.html>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef lm_mcr(x, y, weights, intercept):\n    \n    coef = np.matrix(lm_coef(x, y, weights, intercept)).T\n    rsq = lm_rsq(x, y, weights, intercept)\n        \n    if (intercept): x = sm.add_constant(x)\n    \n#     sigma = np.cov(np.concatenate((x, y), axis = 1).T,\n#                    aweights = weights.reshape(-1))\n    sigma = cov_wt(np.concatenate((x, y), axis = 1), weights, intercept)\n    mcr = np.multiply(coef, np.dot(sigma[:-1, :-1], coef)) / np.sqrt(sigma[-1, -1])\n    mcr_eps = np.sqrt(sigma[-1, -1]) - sum(mcr)\n    \n    result = np.concatenate((np.sqrt(np.matrix(sigma[-1, -1])),\n                             np.matrix(mcr).T,\n                             np.matrix(mcr_eps)), axis = 1)\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlm_mcr(overlap_x_df, overlap_y_df, weights, intercept) * np.sqrt(scale[\"periods\"]) * np.sqrt(scale[\"overlap\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([ 0.06947363, -0.        ,  0.02086819,  0.00379013,  0.01756083,\n        0.01472782,  0.01252666])\n```\n\n\n:::\n:::\n\n\n# Scenario analysis\n\n## Implied shocks\n\n$$\n\\begin{aligned}\n\\hat{\\beta}&=(Z^\\mathrm{T}WZ)^{-1}Z^\\mathrm{T}WX\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef implied_shocks(shocks, x, z, weights):\n\n    beta = np.linalg.lstsq(np.multiply(weights, z), np.multiply(weights, x), rcond = None)[0]\n                     \n    result = np.dot(shocks, beta)\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nshocks = np.array([-0.1, 0.1])\noverlap_z_df = overlap_x_df.iloc[:, [0, 1]]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimplied_shocks(shocks, overlap_x_df, overlap_z_df, weights)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([-0.1       ,  0.1       , -0.00921207, -0.00454814])\n```\n\n\n:::\n:::\n\n\n## Stress P&L\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pnl_stress(shocks, x, y, z, weights, intercept):\n    \n    coef = lm_coef(x, y, weights, intercept)\n    \n    if (intercept): x = sm.add_constant(x)\n    \n    result = np.multiply(coef.T, implied_shocks(shocks, x, z, weights))\n    \n    return np.ravel(result)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npnl_stress(shocks, overlap_x_df, overlap_y_df, overlap_z_df, weights, intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([ 0.00022783, -0.02092612, -0.01225168, -0.02738417, -0.00771866])\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}