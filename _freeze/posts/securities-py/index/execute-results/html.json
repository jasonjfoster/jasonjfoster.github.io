{
  "hash": "81a1113c4146b9e07d02a08dfddfb993",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Securities\"\nauthor: \"[Jason Foster](mailto:jason.j.foster@gmail.com)\"\ndate: last-modified\ncategories:\n  - analysis\n  - finance\n  - python\n---\n\n::: {.cell}\n\n```{.python .cell-code}\nfactors_r = [\"SP500\", \"DTWEXAFEGS\"] # \"SP500\" does not contain dividends; note: \"DTWEXM\" discontinued as of Jan 2020\nfactors_d = [\"DGS10\", \"BAMLH0A0HYM2\"]\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n# Black-Scholes model\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import norm\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef level_shock(shock, S, tau, sigma):\n    \n    result = S * (1 + shock * sigma * np.sqrt(tau))\n    \n    return result\n```\n:::\n\n\n-   <https://en.wikipedia.org/wiki/Greeks_(finance)>\n-   <https://www.wolframalpha.com/input/?i=option+pricing+formula>\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfactor = \"SP500\"\ntypes = [\"call\", \"put\"]\nS = levels_df.ffill()[factor].iloc[-1]\nK = S\nr = 0 # use \"USD3MTD156N\"\nq = 0 # see https://stackoverflow.com/a/11286679 \ntau = 1 # = 252 / 252\nsigma = sd_df[factor].iloc[-1] # use \"VIXCLS\"\nshocks = [x / 2 for x in range(-6, 7)]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngreeks_df = pd.DataFrame([(x, y) for x in types for y in shocks], \n    columns = [\"type\", \"shock\"])\ngreeks_df[\"spot\"] = level_shock(greeks_df[\"shock\"], S, tau, sigma)\n```\n:::\n\n\n## Value\n\nFor a given spot price $S$, strike price $K$, risk-free rate $r$, annual dividend yield $q$, time-to-maturity $\\tau = T - t$, and volatility $\\sigma$:\n\n$$\n\\begin{aligned}\nV_{c}&=Se^{-q\\tau}\\Phi(d_{1})-e^{-r\\tau}K\\Phi(d_{2}) \\\\\nV_{p}&=e^{-r\\tau}K\\Phi(-d_{2})-Se^{-q\\tau}\\Phi(-d_{1})\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_value(type, S, K, r, q, tau, sigma, d1, d2):\n    \n    if (type == \"call\"):\n        result =  S * np.exp(-q * tau) * Phi(d1) - np.exp(-r * tau) * K * Phi(d2)\n    elif (type == \"put\"):\n        result = np.exp(-r * tau) * K * Phi(-d2) - S * np.exp(-q * tau) * Phi(-d1)\n        \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_value(type, S, K, r, q, tau, sigma, d1, d2):\n    \n    r_df = np.exp(-r * tau)\n    q_df = np.exp(-q * tau)\n    \n    call_value = S * q_df * Phi(d1) - r_df * K * Phi(d2)\n    put_value = r_df * K * Phi(-d2) - S * q_df * Phi(-d1)\n    result = np.where(type == \"call\", call_value, put_value)\n    \n    return result\n```\n:::\n\n\nwhere\n\n$$\n\\begin{aligned}\nd_{1}&={\\frac{\\ln(S/K)+(r-q+\\sigma^{2}/2)\\tau}{\\sigma{\\sqrt{\\tau}}}} \\\\\nd_{2}&={\\frac{\\ln(S/K)+(r-q-\\sigma^{2}/2)\\tau}{\\sigma{\\sqrt{\\tau}}}}=d_{1}-\\sigma{\\sqrt{\\tau}} \\\\\n\\phi(x)&={\\frac{e^{-{\\frac {x^{2}}{2}}}}{\\sqrt{2\\pi}}} \\\\\n\\Phi(x)&={\\frac{1}{\\sqrt{2\\pi}}}\\int_{-\\infty}^{x}e^{-{\\frac{y^{2}}{2}}}dy=1-{\\frac{1}{\\sqrt{2\\pi}}}\\int_{x}^{\\infty}e^{-{\\frac{y^{2}}{2}}dy}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_d1(S, K, r, q, tau, sigma):\n    \n    result = (np.log(S / K) + (r - q + sigma ** 2 / 2) * tau) / (sigma * np.sqrt(tau))\n    \n    return result\n\ndef bs_d2(S, K, r, q, tau, sigma):\n    \n    result = (np.log(S / K) + (r - q - sigma ** 2 / 2) * tau) / (sigma * np.sqrt(tau))\n    \n    return result\n    \ndef phi(x):\n    \n    result = norm.pdf(x)\n    \n    return result\n\ndef Phi(x):\n    \n    result = norm.cdf(x)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngreeks_df[\"d1\"] = bs_d1(greeks_df[\"spot\"], K, r, q, tau, sigma)\ngreeks_df[\"d2\"] = bs_d2(greeks_df[\"spot\"], K, r, q, tau, sigma)\ngreeks_df[\"value\"] = bs_value(greeks_df[\"type\"], greeks_df[\"spot\"], K, r, q, tau, sigma,\n                              greeks_df[\"d1\"], greeks_df[\"d2\"]) \n```\n:::\n\n\n## First-order\n\n### Delta\n\n$$\n\\begin{aligned}\n\\Delta_{c}&={\\frac{\\partial V_{c}}{\\partial S}}=e^{-q\\tau}\\Phi(d_{1}) \\\\\n\\Delta_{p}&={\\frac{\\partial V_{p}}{\\partial S}}=-e^{-q\\tau}\\Phi(-d_{1})\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_delta(type, S, K, r, q, tau, sigma, d1, d2):\n  \n    q_df = np.exp(-q * tau)\n    \n    call_value = q_df * Phi(d1)\n    put_value = -q_df * Phi(-d1)\n    result = np.where(type == \"call\", call_value, put_value)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngreeks_df[\"delta\"] = bs_delta(greeks_df[\"type\"], greeks_df[\"spot\"], K, r, q, tau, sigma,\n                              greeks_df[\"d1\"], greeks_df[\"d2\"]) \n```\n:::\n\n\n### Delta-beta\n\nNotional market value is the market value of a leveraged position:\n\n$$\n\\begin{aligned}\n\\text{Equity options }=&\\,\\#\\text{ contracts}\\times\\text{multiple}\\times\\text{spot price}\\\\\n\\text{Delta-adjusted }=&\\,\\#\\text{ contracts}\\times\\text{multiple}\\times\\text{spot price}\\times\\text{delta}\n\\end{aligned}\n$$\n\n-   <https://en.wikipedia.org/wiki/Notional_amount>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_delta_diff(type, S, K, r, q, tau, sigma, delta0):\n    \n    d1 = bs_d1(S, K, r, q, tau, sigma)\n    d2 = bs_d2(S, K, r, q, tau, sigma)\n    delta = bs_delta(type, S, K, r, q, tau, sigma, d1, d2)\n    \n    call_value = delta - delta0\n    put_value = delta0 - delta\n    \n    result = np.where(type == \"call\", call_value, put_value)\n        \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nbeta = 0.35\ntype = \"call\"\nn = 1\nmultiple = 100\ntotal = 1000000\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nd1 = bs_d1(S, K, r, q, tau, sigma)\nd2 = bs_d2(S, K, r, q, tau, sigma)\nsec = {\n    \"n\": n,\n    \"multiple\": multiple,\n    \"S\": S,\n    \"delta\": bs_delta(type, S, K, r, q, tau, sigma, d1, d2),\n    \"beta\": 1\n}\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nbeta_df = pd.DataFrame([(x, y) for x in types for y in shocks], \n    columns = [\"type\", \"shock\"])\nbeta_df[\"spot\"] = level_shock(beta_df[\"shock\"], S, tau, sigma)\nbeta_df[\"static\"] = beta\nbeta_df[\"diff\"] = bs_delta_diff(type, beta_df[\"spot\"], K, r, q, tau, sigma, sec[\"delta\"])\nbeta_df[\"dynamic\"] = beta + sec[\"n\"] * sec[\"multiple\"] * sec[\"S\"] * sec[\"beta\"] * beta_df[\"diff\"] / total\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=384}\n:::\n:::\n\n\nFor completeness, duration equivalent is defined as:\n\n$$\n\\begin{aligned}\n\\text{10-year equivalent }=\\,&\\frac{\\text{security duration}}{\\text{10-year OTR duration}}\n\\end{aligned}\n$$\n\n### Vega\n\n$$\n\\begin{aligned}\n\\nu_{c,p}&={\\frac{\\partial V_{c,p}}{\\partial\\sigma}}=Se^{-q\\tau}\\phi(d_{1}){\\sqrt{\\tau}}=Ke^{-r\\tau}\\phi(d_{2}){\\sqrt{\\tau}}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_vega(type, S, K, r, q, tau, sigma, d1, d2):\n    \n    q_df = np.exp(-q * tau)\n    result = S * q_df * phi(d1) * np.sqrt(tau)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngreeks_df[\"vega\"] = bs_vega(greeks_df[\"type\"], greeks_df[\"spot\"], K, r, q, tau, sigma,\n                            greeks_df[\"d1\"], greeks_df[\"d2\"]) \n```\n:::\n\n\n### Theta\n\n$$\n\\begin{aligned}\n\\Theta_{c}&=-{\\frac{\\partial V_{c}}{\\partial \\tau}}=-e^{-q\\tau}{\\frac{S\\phi(d_{1})\\sigma}{2{\\sqrt{\\tau}}}}-rKe^{-r\\tau}\\Phi(d_{2})+qSe^{-q\\tau}\\Phi(d_{1}) \\\\\n\\Theta_{p}&=-{\\frac{\\partial V_{p}}{\\partial \\tau}}=-e^{-q\\tau}{\\frac{S\\phi(d_{1})\\sigma}{2{\\sqrt{\\tau}}}}+rKe^{-r\\tau}\\Phi(-d_{2})-qSe^{-q\\tau}\\Phi(-d_{1})\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_theta(type, S, K, r, q, tau, sigma, d1, d2):\n    \n    r_df = np.exp(-r * tau)\n    q_df = np.exp(-q * tau)\n    \n    call_value = -q_df * S * phi(d1) * sigma / (2 * np.sqrt(tau)) - \\\n        r * K * r_df * Phi(d2) + q * S * q_df * Phi(d1)\n        \n    put_value = -q_df * S * phi(d1) * sigma / (2 * np.sqrt(tau)) + \\\n        r * K * r_df * Phi(-d2) - q * S * q_df * Phi(-d1)\n        \n    result = np.where(type == \"call\", call_value, put_value)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngreeks_df[\"theta\"] = bs_theta(greeks_df[\"type\"], greeks_df[\"spot\"], K, r, q, tau, sigma,\n                              greeks_df[\"d1\"], greeks_df[\"d2\"]) \n```\n:::\n\n\n## Second-order\n\n### Gamma\n\n$$\n\\begin{aligned}\n\\Gamma_{c,p}&={\\frac{\\partial\\Delta_{c,p}}{\\partial S}}={\\frac{\\partial^{2}V_{c,p}}{\\partial S^{2}}}=e^{-q\\tau}{\\frac{\\phi(d_{1})}{S\\sigma{\\sqrt{\\tau}}}}=Ke^{-r\\tau}{\\frac{\\phi(d_{2})}{S^{2}\\sigma{\\sqrt{\\tau}}}}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef bs_gamma(type, S, K, r, q, tau, sigma, d1, d2):\n  \n    q_df = np.exp(-q * tau)\n    \n    result = q_df * phi(d1) / (S * sigma * np.sqrt(tau))\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngreeks_df[\"gamma\"] = bs_gamma(greeks_df[\"type\"], greeks_df[\"spot\"], K, r, q, tau, sigma,\n                              greeks_df[\"d1\"], greeks_df[\"d2\"]) \n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=960}\n:::\n:::\n\n\n# Taylor series\n\n## First-order\n\n### Price-yield formula\n\nFor a function of one variable, $f(x)$, the Taylor series formula is:\n\n$$\n\\begin{aligned}\nf(x+\\Delta x)&=f(x)+{\\frac{f'(x)}{1!}}\\Delta x+{\\frac{f''(x)}{2!}}(\\Delta x)^{2}+{\\frac{f^{(3)}(x)}{3!}}(\\Delta x)^{3}+\\cdots+{\\frac{f^{(n)}(x)}{n!}}(\\Delta x)^{n}+\\cdots\\\\\nf(x+\\Delta x)-f(x)&={\\frac{f'(x)}{1!}}\\Delta x+{\\frac{f''(x)}{2!}}(\\Delta x)^{2}+{\\frac{f^{(3)}(x)}{3!}}(\\Delta x)^{3}+\\cdots+{\\frac{f^{(n)}(x)}{n!}}(\\Delta x)^{n}+\\cdots\n\\end{aligned}\n$$\n\nUsing the price-yield formula, the estimated percentage change in price for a change in yield is:\n\n$$\n\\begin{aligned}\nP(y+\\Delta y)-P(y)&\\approx{\\frac{P'(y)}{1!}}\\Delta y+{\\frac{P''(y)}{2!}}(\\Delta y)^{2}\\\\\n&\\approx -D\\Delta y +{\\frac{C}{2!}}(\\Delta y)^{2}\n\\end{aligned}\n$$\n\nBecause of market conventions, use the following formula: $P(y+\\Delta y)-P(y)\\approx -D\\Delta y +{\\frac{C\\times 100}{2!}}(\\Delta y)^{2}$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pnl_bond(duration, convexity, dy):\n    \n    duration_pnl = -duration * dy\n    convexity_pnl = (convexity * 100 / 2) * dy ** 2\n    income_pnl = dy\n    \n    result = pd.DataFrame({\n        \"total\": duration_pnl + convexity_pnl + income_pnl,\n        \"duration\": duration_pnl,\n        \"convexity\": convexity_pnl,\n        \"income\": income_pnl\n    })\n    \n    return result\n```\n:::\n\n\n-   <https://engineering.nyu.edu/sites/default/files/2021-07/CarWuRF2021.pdf>\n-   <https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118267967.app1>\n-   <https://www.investopedia.com/terms/c/convexity-adjustment.asp>\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfactor = \"DGS10\"\nduration = 6.5\nconvexity = 0.65\ny = levels_df.ffill()[factor].iloc[-width]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nbond_df = pd.DataFrame({\n    \"duration\": duration,\n    \"convexity\": convexity,\n    \"dy\": (levels_df.ffill()[factor].iloc[-width:] - y) / 100\n})\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nattrib_df = pnl_bond(bond_df[\"duration\"], bond_df[\"convexity\"], bond_df[\"dy\"])\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=576}\n:::\n:::\n\n\n### Duration-yield formula\n\nThe derivative of duration with respect to interest rates gives:\n\n$$\n\\begin{aligned}\n\\text{Drift}&=-\\frac{\\partial D}{\\partial y}\\\\\n&=\\frac{1}{P}\\frac{\\partial^{2}P}{\\partial y^{2}}-\\frac{1}{P^{2}}\\frac{\\partial P}{\\partial y}\\frac{\\partial P}{\\partial y}\\\\\n&=C-D^{2}\n\\end{aligned}\n$$\n\nBecause of market conventions, use the following formula: $\\text{Drift}=\\frac{1}{100}\\left(C\\times 100-D^{2}\\right)=C-\\frac{D^{2}}{100}$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef yield_shock(shock, tau, sigma):\n    \n    result = shock * sigma * np.sqrt(tau)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef duration_drift(duration, convexity, dy):\n    \n    drift = convexity - duration ** 2 / 100\n    change = -drift * dy * 100\n    \n    result = {\n        \"drift\": drift,\n        \"change\": change\n    }\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# \"Risk Management: Approaches for Fixed Income Markets\" (page 45)\nfactor = \"DGS10\"\nsigma = sd_df[factor].iloc[-1]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nduration_df = pd.DataFrame(shocks).rename(columns = {0: \"shock\"})\nduration_df[\"spot\"] = yield_shock(duration_df[\"shock\"], tau, sigma)\nduration_df[\"static\"] = duration\nduration_df[\"dynamic\"] = duration + \\\n    duration_drift(duration, convexity, duration_df[\"spot\"])[\"change\"]\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-36-1.png){width=384}\n:::\n:::\n\n\n## Second-order\n\n### Black's formula\n\nA similar formula holds for functions of several variables $f(x_{1},\\ldots,x_{n})$. This is usually written as:\n\n$$\n\\begin{aligned}\nf(x_{1}+\\Delta x_{1},\\ldots,x_{n}+\\Delta x_{n})&=f(x_{1},\\ldots, x_{n})+ \\sum _{j=1}^{n}{\\frac{\\partial f(x_{1},\\ldots,x_{n})}{\\partial x_{j}}}(\\Delta x_{j})\\\\\n&+{\\frac {1}{2!}}\\sum_{j=1}^{n}\\sum_{k=1}^{n}{\\frac{\\partial^{2}f(x_{1},\\ldots,x_{d})}{\\partial x_{j}\\partial x_{k}}}(\\Delta x_{j})(\\Delta x_{k})+\\cdots\n\\end{aligned}\n$$\n\nUsing Black's formula, the estimated change of an option price is:\n\n$$\n\\begin{aligned}\nV(S+\\Delta S,\\sigma+\\Delta\\sigma,t+\\Delta t)-V(S,\\sigma,t)&\\approx{\\frac{\\partial V}{\\partial S}}\\Delta S+{\\frac{1}{2!}}{\\frac{\\partial^{2}V}{\\partial S^{2}}}(\\Delta S)^{2}+{\\frac{\\partial V}{\\partial \\sigma}}\\Delta\\sigma+{\\frac{\\partial V}{\\partial t}}\\Delta t\\\\\n&\\approx \\Delta_{c,p}\\Delta S+{\\frac{1}{2!}}\\Gamma_{c,p}(\\Delta S)^{2}+\\nu_{c,p}\\Delta\\sigma+\\Theta_{c,p}\\Delta t\n\\end{aligned}\n$$\n\n-   <https://quant-next.com/option-greeks-and-pl-decomposition-part-1/>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pnl_option(type, S, K, r, q, tau, sigma, dS, dt, dsigma):\n    \n    d1 = bs_d1(S, K, r, q, tau, sigma)\n    d2 = bs_d2(S, K, r, q, tau, sigma)\n    value = bs_value(type, S, K, r, q, tau, sigma, d1, d2)\n    delta = bs_delta(type, S, K, r, q, tau, sigma, d1, d2)\n    vega = bs_vega(type, S, K, r, q, tau, sigma, d1, d2)\n    theta = bs_theta(type, S, K, r, q, tau, sigma, d1, d2)\n    gamma = bs_gamma(type, S, K, r, q, tau, sigma, d1, d2)\n    \n    delta_pnl = delta * dS / value\n    gamma_pnl = gamma / 2 * dS ** 2 / value\n    vega_pnl = vega * dsigma / value\n    theta_pnl = theta * dt / value\n    \n    result = pd.DataFrame({\n        \"total\": delta_pnl + gamma_pnl + vega_pnl + theta_pnl,\n        \"delta\": delta_pnl,\n        \"gamma\": gamma_pnl,\n        \"vega\": vega_pnl,\n        \"theta\": theta_pnl\n    })\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfactor = \"SP500\"\ntype = \"call\"\nS = levels_df.ffill()[factor].iloc[-width]\nK = S # * (1 + 0.05)\ntau = 1 # = 252 / 252\nsigma = sd_df[factor].iloc[-width]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\noptions_df = pd.DataFrame({\n    \"spot\": levels_df.ffill()[factor].iloc[-width:],\n    \"sigma\": sd_df[factor].iloc[-width:]\n})\noptions_df[\"dS\"] = options_df[\"spot\"] - S\noptions_df[\"dt_diff\"] = (options_df.index - options_df.index[0]).days\noptions_df[\"dt\"] = options_df[\"dt_diff\"] / options_df[\"dt_diff\"].iloc[-1]\noptions_df[\"dsigma\"] = options_df[\"sigma\"] - sigma\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nattrib_df = pnl_option(type, S, K, r, q, tau, sigma,\n                       options_df[\"dS\"], options_df[\"dt\"], options_df[\"dsigma\"])\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-41-1.png){width=576}\n:::\n:::\n\n\n### Ito's lemma\n\nFor a given diffiusion $X(t, w)$ driven by:\n\n$$\n\\begin{aligned}\ndX_{t}&=\\mu_{t}dt+\\sigma_{t}dB_{t}\n\\end{aligned}\n$$\n\nThen proceed with the Taylor series for a function of two variables $f(t,x)$:\n\n$$\n\\begin{aligned}\ndf&={\\frac{\\partial f}{\\partial t}}dt+{\\frac{\\partial f}{\\partial x}}dx+{\\frac{1}{2}}{\\frac{\\partial^{2}f}{\\partial x^{2}}}dx^{2}\\\\\n&={\\frac{\\partial f}{\\partial t}}dt+{\\frac{\\partial f}{\\partial x}}(\\mu_{t}dt+\\sigma_{t}dB_{t})+{\\frac{1}{2}}{\\frac{\\partial^{2}f}{\\partial x^{2}}}\\left(\\mu_{t}^{2}dt^{2}+2\\mu_{t}\\sigma _{t}dtdB_{t}+\\sigma_{t}^{2}dB_{t}^{2}\\right)\\\\\n&=\\left({\\frac{\\partial f}{\\partial t}}+\\mu_{t}{\\frac{\\partial f}{\\partial x}}+{\\frac{\\sigma _{t}^{2}}{2}}{\\frac{\\partial ^{2}f}{\\partial x^{2}}}\\right)dt+\\sigma_{t}{\\frac{\\partial f}{\\partial x}}dB_{t}\n\\end{aligned}\n$$\n\nNote: set the $dt^{2}$ and $dtdB_{t}$ terms to zero and substitute $dt$ for $dB^{2}$.\n\n### Geometric Brownian motion\n\nThe most common application of Ito's lemma in finance is to start with the percent change of an asset:\n\n$$\n\\begin{aligned}\n\\frac{dS}{S}&=\\mu_{t}dt+\\sigma_{t}dB_{t}\n\\end{aligned}\n$$\n\nThen apply Ito's lemma with $f(S)=log(S)$:\n\n$$\n\\begin{aligned}\nd\\log(S)&=f^{\\prime}(S)dS+{\\frac{1}{2}}f^{\\prime\\prime}(S)S^{2}\\sigma^{2}dt\\\\\n&={\\frac {1}{S}}\\left(\\sigma SdB+\\mu Sdt\\right)-{\\frac{1}{2}}\\sigma^{2}dt\\\\\n&=\\sigma dB+\\left(\\mu-{\\tfrac{\\sigma^{2}}{2}}\\right)dt\n\\end{aligned}\n$$\n\nIt follows that:\n\n$$\n\\begin{aligned}\n\\log(S_{t})-\\log(S_{0})=\\sigma dB+\\left(\\mu-{\\tfrac{\\sigma^{2}}{2}}\\right)dt\n\\end{aligned}\n$$\n\nExponentiating gives the expression for $S$:\n\n$$\n\\begin{aligned}\nS_{t}=S_{0}\\exp\\left(\\sigma B_{t}+\\left(\\mu-{\\tfrac{\\sigma^{2}}{2}}\\right)t\\right)\n\\end{aligned}\n$$\n\nThis provides a recursive procedure for simulating values of $S$ at $t_{0}<t_{1}<\\cdots<t_{n}$:\n\n$$\n\\begin{aligned}\nS(t_{i+1})&=S(t_{i})\\exp\\left(\\sigma\\sqrt{t_{i+1}-t_{i}}Z_{i+1}+\\left[\\mu-{\\tfrac{\\sigma^{2}}{2}}\\right]\\left(t_{i+1}-t_{i}\\right)\\right)\n\\end{aligned}\n$$\n\nwhere $Z_{1},Z_{2},\\ldots,Z_{n}$ are independent standard normals.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef sim_gbm(n_sim, S, mu, sigma, dt):\n    \n    result = S * np.exp(np.cumsum(sigma * np.sqrt(dt) * np.random.normal(size = n_sim)) + \\\n                        (mu - 0.5 * sigma ** 2) * dt)\n    \n    return result\n```\n:::\n\n\nThis leads to an algorithm for simulating a multidimensional geometric Brownian motion:\n\n$$\n\\begin{aligned}\nS_{k}(t_{i+1})&=S_{k}(t_{i})\\exp\\left(\\sqrt{t_{i+1}-t_{i}}\\sum_{j=1}^{d}{A_{kj}Z_{i+1,j}}+\\left[\\mu_{k}-{\\tfrac{\\sigma_{k}^{2}}{2}}\\right]\\left(t_{i+1}-t_{i}\\right)\\right)\n\\end{aligned}\n$$\n\nwhere $A$ is the Cholesky factor of $\\Sigma$, i.e. $A$ is any matrix for which $AA^\\mathrm{T}=\\Sigma$.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef sim_multi_gbm(n_sim, S, mu, sigma, dt):\n    \n    n_cols = sigma.shape[1]\n    \n    Z = np.random.normal(size = n_sim * n_cols).reshape((n_sim, n_cols))\n    X = np.sqrt(dt) * Z @ np.linalg.cholesky(sigma).T + (mu - 0.5 * np.diag(sigma)) * dt\n    \n    result = S * np.exp(X.cumsum(axis = 0))\n    \n    return np.asmatrix(result)\n```\n:::\n\n\n-   <https://arxiv.org/pdf/0812.4210.pdf>\n-   <https://quant.stackexchange.com/questions/15219/calibration-of-a-gbm-what-should-dt-be>\n-   <https://stackoverflow.com/questions/36463227/geometrical-brownian-motion-simulation-in-r>\n-   <https://quant.stackexchange.com/questions/25219/simulate-correlated-geometric-brownian-motion-in-the-r-programming-language>\n-   <https://quant.stackexchange.com/questions/35194/estimating-the-historical-drift-and-volatility/>\n\n\n::: {.cell}\n\n```{.python .cell-code}\nS = [1] * len(factors)\nsigma = np.cov(returns_df[\"returns\"].dropna().T, ddof = 1) * scale[\"periods\"]\nmu = np.array(returns_df[\"returns\"].dropna().mean()) * scale[\"periods\"]\nmu = mu + np.diag(sigma) / 2 # drift\ndt = 1 / scale[\"periods\"]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nmu_ls = []\nsigma_ls = []\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfor i in range(10000): # \"TypeError: 'float' object cannot be interpreted as an integer\"\n  \n    # assumes underlying stock price follows geometric Brownian motion with constant volatility\n    levels_sim = pd.DataFrame(sim_multi_gbm(width + 1, S, mu, sigma, dt))\n    returns_sim = np.log(levels_sim).diff()\n\n    mu_sim = returns_sim.mean() * scale[\"periods\"]\n    sigma_sim = returns_sim.std() * np.sqrt(scale[\"periods\"])\n\n    mu_ls.append(mu_sim)\n    sigma_ls.append(sigma_sim)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nmu_df = pd.DataFrame(mu_ls)\nsigma_df = pd.DataFrame(sigma_ls)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npd.DataFrame({\n    \"empirical\": np.array(returns_df[\"returns\"].dropna().mean()) * scale[\"periods\"],\n    \"theoretical\": mu_df.mean()\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   empirical  theoretical\n0   0.101232     0.100856\n1   0.016681     0.016616\n2  -0.000887    -0.000982\n3   0.001644     0.001715\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npd.DataFrame({\n    \"empirical\": np.sqrt(np.diag(sigma)),\n    \"theoretical\": sigma_df.mean()\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   empirical  theoretical\n0   0.179441     0.179316\n1   0.062626     0.062542\n2   0.008346     0.008343\n3   0.016956     0.016939\n```\n\n\n:::\n:::\n\n\n### Vasicek model\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# assumes interest rates follow mean-reverting process with stochastic volatility\n```\n:::\n\n\n# Newton's method\n\n## Implied volatility\n\nNewton's method (main idea is also from a Taylor series) is a method for finding approximations to the roots of a function $f(x)$:\n\n$$\n\\begin{aligned}\nx_{n+1}=x_{n}-{\\frac{f(x_{n})}{f'(x_{n})}}\n\\end{aligned}\n$$\n\nTo solve $V(\\sigma_{n})-V=0$ for $\\sigma_{n}$, use Newton's method and repeat until $\\left|\\sigma_{n+1}-\\sigma_{n}\\right|<\\varepsilon$:\n\n$$\n\\begin{aligned}\n\\sigma_{n+1}=\\sigma_{n}-{\\frac{V(\\sigma_{n})-V}{V'(\\sigma_{n})}}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef implied_vol_newton(params, type, S, K, r, q, tau):\n    \n    target0 = 0\n    sigma = params[\"sigma\"]\n    sigma0 = sigma\n    \n    while (abs(target0 - params[\"target\"]) > params[\"tol\"]):\n        \n        d1 = bs_d1(S, K, r, q, tau, sigma0)\n        d2 = bs_d2(S, K, r, q, tau, sigma0)\n        \n        target0 = bs_value(type, S, K, r, q, tau, sigma0, d1, d2)\n        d_target0 = bs_vega(type, S, K, r, q, tau, sigma0, d1, d2)\n        \n        sigma = sigma0 - (target0 - params[\"target\"]) / d_target0\n        sigma0 = sigma\n        \n    return sigma\n```\n:::\n\n\n-   <http://www.aspenres.com/documents/help/userguide/help/bopthelp/bopt2Implied_Volatility_Formula.html>\n-   <https://books.google.com/books?id=VLi61POD61IC&pg=PA104>\n\n\n::: {.cell}\n\n```{.python .cell-code}\nS = levels_df.ffill()[factor].iloc[-1]\nK = S # * (1 + 0.05)\nsigma = sd_df[factor].iloc[-1] # overrides matrix\nstart1 = 0.2\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nd1 = bs_d1(S, K, r, q, tau, sigma)\nd2 = bs_d2(S, K, r, q, tau, sigma)\ntarget1 = bs_value(type, S, K, r, q, tau, sigma, d1, d2)\nparams1 = {\n    \"target\": target1,\n    \"sigma\": start1,\n    \"tol\": 1e-4 # np.finfo(float).eps\n}\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimplied_vol_newton(params1, type, S, K, r, q, tau) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.1234596132919894\n```\n\n\n:::\n:::\n\n\n## Yield-to-maturity\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef yld_newton(params, cash_flows):\n    \n    target0 = 0\n    yld0 = params[\"cpn\"] / params[\"freq\"]\n    yld = yld0 # assignment to `yield` variable is not possible\n    \n    while (abs(target0 - params[\"target\"]) > params[\"tol\"]):\n        \n        target0 = 0\n        d_target0 = 0\n        dd_target0 = 0\n        \n        for i in range(len(cash_flows)):\n          \n            t = i + 1\n          \n            # present value of cash flows\n            target0 += cash_flows[i] / (1 + yld0) ** t\n            \n            # first derivative of present value of cash flows\n            d_target0 -= t * cash_flows[i] / (1 + yld0) ** (t + 1) # use t for Macaulay duration\n            \n            # second derivative of present value of cash flows\n            dd_target0 -= t * (t + 1) * cash_flows[i] / (1 + yld0) ** (t + 2)\n        \n        yld = yld0 - (target0 - params[\"target\"]) / d_target0\n        yld0 = yld\n        \n    result = {\n        \"price\": target0,\n        \"yield\": yld * params[\"freq\"],\n        \"duration\": -d_target0 / params[\"target\"] / params[\"freq\"],\n        \"convexity\": -dd_target0 / params[\"target\"] / params[\"freq\"] ** 2\n    }\n        \n    return result\n```\n:::\n\n\n-   <https://www.bloomberg.com/markets/rates-bonds/government-bonds/us>\n-   <https://quant.stackexchange.com/a/61025>\n-   <https://pages.stern.nyu.edu/~igiddy/spreadsheets/duration-convexity.xls>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntarget2 = 0.9928 * 1000 # present value\nstart2 = 0.0438 # coupon\ncash_flows = [start2 * 1000 / 2] * 10 * 2\ncash_flows[-1] += 1000\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nparams2 = {\n    \"target\": target2,\n    \"cpn\": start2,\n    \"freq\": 2,\n    \"tol\": 1e-4 # np.finfo(float).eps\n}\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nyld_newton(params2, cash_flows)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{'price': 992.8000005704454, 'yield': 0.044700757710159994, 'duration': 8.0165959605043, 'convexity': 76.68109754287481}\n```\n\n\n:::\n:::\n\n\n# Optimization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.optimize import minimize\n```\n:::\n\n\n## Implied volatility\n\nIf the derivative is unknown, try optimization:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef implied_vol_obj(param, type, S, K, r, q, tau, target):\n    \n    d1 = bs_d1(S, K, r, q, tau, param)\n    d2 = bs_d2(S, K, r, q, tau, param)\n    target0 = bs_value(type, S, K, r, q, tau, param, d1, d2)\n    \n    result = abs(target0 - target)\n    \n    return result\n\ndef implied_vol_optim(param, type, S, K, r, q, tau, target):\n    \n    result = minimize(implied_vol_obj, param, args = (type, S, K, r, q, tau, target))\n    \n    return result.x.item()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimplied_vol_optim(start1, type, S, K, r, q, tau, target1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.12345960733818702\n```\n\n\n:::\n:::\n\n\n## Yield-to-maturity\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef yld_obj(param, cash_flows, target):\n    \n    target0 = 0\n    \n    for i in range(len(cash_flows)):\n        \n        target0 += cash_flows[i] / (1 + param) ** (i + 1)\n    \n    target0 = abs(target0 - target)\n    \n    return target0\n  \ndef yld_optim(params, cash_flows, target):\n    \n    result = minimize(yld_obj, params[\"cpn\"], args = (cash_flows, target))\n    \n    return result.x.item() * params[\"freq\"]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nyld_optim(params2, cash_flows, target2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.04470075001603727\n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}