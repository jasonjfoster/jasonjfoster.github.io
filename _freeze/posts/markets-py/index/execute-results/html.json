{
  "hash": "120af50258d7fe7bdaee5af3b9136bf8",
  "result": {
    "markdown": "---\ntitle: \"Markets\"\nauthor: \"[Jason Foster](mailto:jason.j.foster@gmail.com)\"\ndate: last-modified\ncategories:\n  - analysis\n  - finance\n  - python\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(data.table)\nsource(\"../plot/theme_jjf.R\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport pandas_datareader as pdr\nfrom scipy.stats import norm, chi2\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfactors_r = [\"SP500\", \"DTWEXAFEGS\"] # \"SP500\" does not contain dividends; note: \"DTWEXM\" discontinued as of Jan 2020\nfactors_d = [\"DGS10\", \"BAMLH0A0HYM2\"]\nfactors = factors_r + factors_d\nwidth = 252\nscale = {\"periods\": 252, \"overlap\": 5}\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n* <https://pandas-datareader.readthedocs.io/en/latest/remote_data.html>\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlevels_df = pdr.get_data_fred(factors, start = \"1900-01-01\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nreturns_df = levels_df.apply(lambda x: np.log(x).diff() if x.name in factors_r else -x.diff() / 100)\noverlap_df = returns_df.rolling(scale[\"overlap\"], min_periods = 1).mean()\nreturns_df = pd.concat([returns_df, overlap_df], keys = [\"returns\", \"overlap\"], axis = 1)\n```\n:::\n\n\n# Price momentum\n\nOne month reversal and 2-12 month momentum are two ends of the spectrum. The general trend indicates that positive acceleration leads to reversals or negative acceleration leads to rebounds. An unsustainable acceleration leading to reversal can reconcile the one-month reversal and 2-12 month momentum. The key is that it implies that acceleration is not sustainable.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# \"Momentum, Acceleration, and Reversal\"\ndef pnl(x):\n    return np.nanprod(1 + x) - 1\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\norder = 20\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nmomentum_df = returns_df[\"returns\"].shift(order).rolling(width - order, min_periods = 1).apply(pnl, raw = False).dropna()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmomentum_mlt <- melt(as.data.table(py$momentum_df, keep.rownames = \"index\"), id.vars = \"index\")\nmomentum_mlt[ , index := as.Date(index)]\nmomentum_plt <- plot_ts_decomp(momentum_mlt, decomp = \"Total\", title = \"Momentum 1Y (%)\") +\n  facet_wrap(~ variable, scales = \"free\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n```\n:::\n\n```{.r .cell-code}\nprint(momentum_plt)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=768}\n:::\n:::\n\n\n# Time-series score\n\nSuppose we are looking at $n$ independent and identically distributed random variables, $X_{1},X_{2},\\ldots,X_{n}$. Since they are iid, each random variable $X_{i}$ has to have the same mean, which we will call $\\mu$, and variance, which we will call $\\sigma^{2}$:\n\n$$\n\\begin{aligned}\n\\mathrm{E}\\left(X_{i}\\right)&=\\mu\\\\\n\\mathrm{Var}\\left(X_{i}\\right)&=\\sigma^{2}\n\\end{aligned}\n$$\n\nLet's suppose we want to look at the average value of our $n$ random variables:\n\n$$\n\\begin{aligned}\n\\bar{X}=\\frac{X_{1}+X_{2}+\\cdots+X_{n}}{n}=\\left(\\frac{1}{n}\\right)\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)\n\\end{aligned}\n$$\n\nWe want to find the expected value and variance of the average, $\\mathrm{E}\\left(\\bar{X}\\right)$ and $\\mathrm{Var}\\left(\\bar{X}\\right)$.\n\n## Expected value\n\n$$\n\\begin{aligned}\n\\mathrm{E}\\left(\\bar{X}\\right)&=\\mathrm{E}\\left[\\left(\\frac{1}{n}\\right)\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)\\right]\\\\\n&=\\left(\\frac{1}{n}\\right)\\mathrm{E}\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)\\\\\n&=\\left(\\frac{1}{n}\\right)\\left(n\\mu\\right)\\\\\n&=\\mu\n\\end{aligned}\n$$\n\n## Variance\n\n$$\n\\begin{aligned}\n\\mathrm{Var}\\left(\\bar{X}\\right)&=\\mathrm{Var}\\left[\\left(\\frac{1}{n}\\right)\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)\\right]\\\\\n&=\\left(\\frac{1}{n}\\right)^{2}\\mathrm{Var}\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)\\\\\n&=\\left(\\frac{1}{n}\\right)^{2}\\left(n\\sigma^{2}\\right)\\\\\n&=\\frac{\\sigma^{2}}{n}\n\\end{aligned}\n$$\n\n* <http://scipp.ucsc.edu/~haber/ph116C/iid.pdf>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef risk(x):\n    \n    n_rows = sum(~np.isnan(x))\n        \n    if n_rows > 1:\n        result = np.sqrt(np.nansum(x ** 2) / (n_rows - 1))\n    else:\n        result = np.nan\n        \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# volatility scale only\nscore_df = (momentum_df / momentum_df.rolling(width, min_periods = 1).apply(risk, raw = False)).dropna()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# overall_df = score_df.mean(axis = 1)\n# overall_df = overall_df / overall_df.rolling(width, min_periods = 1).apply(risk, raw = False)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# score_df.insert(loc = 0, column = \"Overall\", value = overall_df)\n# score_df = score_df.dropna()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nscore_mlt <- melt(as.data.table(py$score_df, keep.rownames = \"index\"), id.vars = \"index\")\nscore_mlt[ , index := as.Date(index)]\nscore_plt <- plot_ts_decomp(score_mlt, decomp = \"Overall\", title = \"Score 1Y\", multiple = 1) +\n  facet_wrap(~ variable)\nprint(score_plt)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n\n# Outlier detection\n\nOutliers are defined the regression residuals that fall below $Q_{1}−1.5\\times IQR$ or above $Q_{3}+1.5\\times IQR$:\n\n* <https://stats.stackexchange.com/a/1153>\n* <https://stats.stackexchange.com/a/108951>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef outliers(z):\n    \n    n_cols = z.shape[1]\n    result = pd.DataFrame()\n    \n    for j in range(n_cols):\n        \n        y = z.iloc[:, j]\n        \n        if (n_cols == 0):\n          x = range(len(y))\n        else:\n          \n          t = range(len(y))\n          x = np.concatenate((np.matrix(t).T, z.drop(z.columns[j], axis = 1)), axis = 1)\n        \n        x = sm.add_constant(x)\n        coef = sm.WLS(y, x).fit().params\n        x = x[:, 1:]\n        \n        predict = coef[0] + np.matmul(coef[1:], x.T)\n        resid = y - np.ravel(predict)\n        \n        lower = resid.quantile(0.25)\n        upper = resid.quantile(0.75)\n        iqr = upper - lower\n        \n        total = y[(resid < lower - 1.5 * iqr) | (resid > upper + 1.5 * iqr)]\n        total = pd.DataFrame({\"date\": total.index, \"symbol\": total.name, \"values\": total})\n        \n        result = result.append(total, ignore_index = True)\n    \n    result = result.pivot_table(index = \"date\", columns = \"symbol\", values = \"values\")\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\noutliers_df = outliers(score_df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noutliers_mlt <- melt(as.data.table(py$outliers_df, keep.rownames = \"index\"), id.vars = \"index\")\noutliers_mlt[ , index := as.Date(index)]\noutliers_plt <- score_plt +\n  geom_point(data = outliers_mlt, aes(x = index, y = value, fill = variable))\nprint(outliers_plt)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=768}\n:::\n:::\n\n\n# Granger causality\n\n$$\n\\begin{aligned}\n\\left(R\\hat{\\beta}-r\\right)^\\mathrm{T}\\left(R\\hat{V}R^\\mathrm{T}\\right)^{-1}\\left(R\\hat{\\beta}-r\\right)\\xrightarrow\\quad\\chi_{Q}^{2}\n\\end{aligned}\n$$\n\n* <https://github.com/cran/lmtest/blob/master/R/waldtest.R>\n* <https://en.wikipedia.org/wiki/Wald_test#Test(s)_on_multiple_parameters>\n* <https://math.stackexchange.com/a/1591946>\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef granger_test(x, y, order):\n    \n    # compute lagged observations\n    lag_x = x.shift(order)\n    lag_y = y.shift(order)\n    \n    # collect series\n    df = pd.DataFrame({\"x\": x, \"y\": y, \"lag_x\": lag_x, \"lag_y\": lag_y})\n    x_mat = sm.add_constant(np.matrix(df[[\"lag_y\", \"lag_x\"]]))\n    y_mat = np.matrix(df[\"y\"]).T\n    \n    # fit full model\n    fit = sm.WLS(y_mat, x_mat, missing = \"drop\").fit()\n    \n    R = np.matrix([0, 0, 1])\n    coef = np.matrix(fit.params)\n    r = 0 # technically a matrix (see Stack Exchange)\n    \n    matmul = np.matmul(R, coef.T) - r\n    maatmul_mid = np.linalg.inv(np.matmul(R, np.matmul(np.matrix(fit.cov_params()), R.T)))\n    wald = np.matmul(matmul.T, np.matmul(maatmul_mid, matmul))\n    \n    result = 1 - chi2.cdf(wald, 1)\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef roll_lead_lag(x, y, width, order, p_value):\n\n    n_rows = len(x)\n    x_name = x.name\n    y_name = y.name\n    result = pd.DataFrame()\n    \n    for i in range(width - 1, n_rows):\n        \n        x_y_status = False\n        y_x_status = False\n        \n        idx = range(max(i - width + 1, 0), i + 1)\n\n        x_y = granger_test(x.iloc[idx], y.iloc[idx], order)\n        y_x = granger_test(y.iloc[idx], x.iloc[idx], order)\n\n        if (x_y < p_value) and (y_x > p_value):\n            x_y_status = True # x leads y\n        elif (x_y > p_value) and (y_x < p_value):\n            y_x_status = True # y leads x\n          \n        # dynamic column names\n        total = pd.DataFrame([[x_y_status, y_x_status]], columns = [x_name, y_name])\n        result = result.append(total, ignore_index = True)\n\n    result.index = x.index[(width - 1):]\n\n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\np_value = 0.05\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nscore_x_df = score_df.loc[:, \"SP500\"]\nscore_y_df = score_df.loc[:, \"DGS10\"]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlead_lag_df = roll_lead_lag(score_x_df, score_y_df, width, order, p_value)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlead_lag_mlt <- melt(as.data.table(py$lead_lag_df, keep.rownames = \"index\"), id.vars = \"index\")\nlead_lag_mlt[ , index := as.Date(index)]\nlead_lag_plt <- plot_ts_decomp(lead_lag_mlt, decomp = \"Total\", title = \"Lead lag 1M\", palette = palette) +\n  theme(axis.text.y = element_blank())\nprint(lead_lag_plt)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=576}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}