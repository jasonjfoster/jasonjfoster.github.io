{
  "hash": "4e19f50b409160a1518a919bc034b23d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Optimization\"\nauthor: \"[Jason Foster](mailto:jason.j.foster@gmail.com)\"\ndate: last-modified\ncategories:\n  - analysis\n  - finance\n  - r\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n# Random weights\n\nNeed to generate uniformly distributed weights $\\mathbf{w}=(w_{1},w_{2},\\ldots,w_{N})$ such that $\\sum_{j=1}^{N}w_{i}=1$ and $w_{i}\\geq0$:\n\n-   **Approach 1**: tempting to use $w_{i}=\\frac{u_{i}}{\\sum_{j=1}^{N}u_{i}}$ where $u_{i}\\sim U(0,1)$ but the distribution of $\\mathbf{w}$ is not uniform\n\n-   **Approach 2**: instead, generate $\\text{Exp}(1)$ and then normalize\n\nCan also scale random weights by $M$, e.g. if sum of weights must be 10% then multiply weights by 10%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrand_weights1 <- function(n_sim, n_assets) {\n    \n    rand_exp <- matrix(runif(n_sim * n_assets), nrow = n_sim, ncol = n_assets)\n    result <- rand_exp / rowSums(rand_exp)\n    \n    return(result)\n    \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn_assets <- 3\nn_sim <- 10000\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\napproach1 <- rand_weights1(n_sim, n_assets)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=384}\n:::\n:::\n\n\n**Approach 2(a)**: uniform sample from the simplex (<http://mathoverflow.net/a/76258>) and then normalize\n\n-   If $u\\sim U(0,1)$ then $-\\ln(u)$ is an $\\text{Exp}(1)$ distribution\n\nThis is also known as generating a random vector from the symmetric Dirichlet distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrand_weights2a <- function(n_sim, n_assets, lmbda) {\n    \n    # inverse transform sampling: https://en.wikipedia.org/wiki/Inverse_transform_sampling\n    rand_exp <- matrix(-log(1 - runif(n_sim * n_assets)) / lmbda, nrow = n_sim, ncol = n_assets)\n    result <- rand_exp / rowSums(rand_exp)\n    \n    return(result)\n    \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlmbda <- 1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\napproach2a <- rand_weights2a(n_sim, n_assets, lmbda)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=384}\n:::\n:::\n\n\n**Approach 2(b)**: directly generate $\\text{Exp}(1)$ and then normalize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrand_weights2b <- function(n_sim, n_assets) {\n    \n    rand_exp <- matrix(rexp(n_sim * n_assets), nrow = n_sim, ncol = n_assets)\n    result <- rand_exp / rowSums(rand_exp)\n    \n    return(result)\n    \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\napproach2b <- rand_weights2b(n_sim, n_assets)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=384}\n:::\n:::\n\n\n## Random turnover\n\nHow to generate random weights between lower bound $a$ and upper bound $b$ that sum to zero?\n\n-   **Approach 1**: tempting to multiply random weights by $M$ and then subtract by $\\frac{M}{N}$ but the distribution is not between $a$ and $b$\n\n-   **Approach 2**: instead, use an iterative approach for random turnover:\n\n    1.  Generate $N-1$ uniformly distributed weights between $a$ and $b$\n    2.  For $u_{N}$ compute sum of values and subtract from $M$\n    3.  If $u_{N}$ is between $a$ and $b$, then keep; otherwise, discard\n\nThen add random turnover to previous period's random weights.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrand_turnover1 <- function(n_sim, n_assets, lower, upper, target) {\n    \n    rng <- upper - lower\n    \n    result <- rand_weights2b(n_sim, n_assets) * rng\n    result <- result - rng / n_assets\n    \n    return(result)\n    \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlower <- -0.05\nupper <- 0.05\ntarget <- 0\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\napproach1 <- rand_turnover1(n_sim, n_assets, lower, upper, target)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=384}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrand_iterative <- function(n_assets, lower, upper, target) {\n    \n    result <- runif(n_assets - 1, min = lower, max = upper)\n    temp <- target - sum(result)\n    \n    while (!((temp <= upper) && (temp >= lower))) {\n        \n        result <- runif(n_assets - 1, min = lower, max = upper)\n        temp <- target - sum(result)\n        \n    }\n    \n    result <- append(result, temp)\n    \n    return(result)\n    \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrand_turnover2 <- function(n_sim, n_assets, lower, upper, target) {\n  \n    result_ls <- list()\n    \n    for (i in 1:n_sim) {\n        \n        result_sim <- rand_iterative(n_assets, lower, upper, target)\n        result_ls <- append(result_ls, list(result_sim))\n        \n    }\n    \n    result <- do.call(rbind, result_ls)\n    \n    return(result)\n    \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\napproach2 <- rand_turnover2(n_sim, n_assets, lower, upper, target)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=384}\n:::\n:::\n\n\n# Mean-variance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(CVXR)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngeometric_mean <- function(x, scale) {\n    \n    result <- prod(1 + x) ^ (scale / length(x)) - 1\n    \n    return(result)\n    \n}\n```\n:::\n\n\n-   <https://www.adrian.idv.hk/2021-06-22-kkt/>\n-   <https://or.stackexchange.com/a/3738>\n-   <https://bookdown.org/compfinezbook/introFinRbook/Portfolio-Theory-with-Matrix-Algebra.html#algorithm-for-computing-efficient-frontier>\n-   <https://palomar.home.ece.ust.hk/MAFS6010R_lectures/slides_robust_portfolio.html>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreturns_x_xts <- na.omit(returns_xts)[ , factors] # extended history\nmu <- apply(returns_x_xts, 2, geometric_mean, scale = scale[[\"periods\"]])\nsigma <- cov(overlap_x_xts) * scale[[\"periods\"]] * scale[[\"overlap\"]]\n```\n:::\n\n\n## Maximize means\n\n$$\n\\begin{aligned}\n\\begin{array}{rrcl}\n\\displaystyle\\min&-\\mathbf{w}^{T}\\mu\\\\\n\\textrm{s.t.}&\\mathbf{w}^{T}e&=&1\\\\\n&\\mathbf{w}^T\\Sigma\\mathbf{w}&\\leq&\\sigma^{2}\\\\\n\\end{array}\n\\end{aligned}\n$$\n\nTo incorporate these conditions into one equation, introduce new variables $\\lambda_{i}$ that are the Lagrange multipliers and define a new function $\\mathcal{L}$ as follows:\n\n$$\n\\begin{aligned}\n\\mathcal{L}(\\mathbf{w},\\lambda)&=-\\mathbf{w}^{T}\\mu-\\lambda_{1}(\\mathbf{w}^{T}e-1)\n\\end{aligned}\n$$\n\nThen, to minimize this function, take derivatives with respect to $w$ and Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial w}&=-\\mu-\\lambda_{1}e=0\\\\\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial \\lambda_{1}}&=\\mathbf{w}e^T-1=0\n\\end{aligned}\n$$\n\nSimplify the equations above in matrix form and solve for the Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\begin{bmatrix}\n-\\mu & e \\\\\ne^{T} & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n0 \\\\\n1\n\\end{bmatrix}\n\\\\\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n-\\mu & e \\\\\ne^{T} & 0\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n0 \\\\\n1\n\\end{bmatrix}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntarget <- 0.06\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmax_mean_optim <- function(mu, sigma, target) {\n    \n    params <- Variable(length(mu))\n    \n    obj <- Maximize(t(params) %*% mu)\n    \n    cons <- list(sum(params) == 1, params >= 0,\n                 quad_form(params, sigma) <= target ^ 2)\n    \n    prob <- Problem(obj, cons)\n    \n    result <- solve(prob)$getValue(params)\n    \n    return(result)\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams1 <- t(max_mean_optim(mu, sigma, target))\nparams1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]     [,2]         [,3]        [,4]\n[1,] 0.480021 0.519979 6.711625e-09 4.42421e-09\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams1 %*% mu\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.04543751\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(params1 %*% sigma %*% t(params1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,] 0.06\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# # install.packages(\"devtools\")\n# devtools::install_github(\"jasonjfoster/rolloptim\") # roll (>= 1.1.7)\n# library(rolloptim)\n# \n# mu <- roll_mean(returns_x_xts, 5)\n# sigma <- roll_cov(returns_x_xts, width = 5)\n# \n# xx <- roll_crossprod(returns_x_xts, returns_x_xts, 5)\n# xy <- roll_crossprod(returns_x_xts, y, 5) # TO DO\n# \n# roll_max_mean(mu)\n```\n:::\n\n\n## Minimize variance\n\n$$\n\\begin{aligned}\n\\begin{array}{rrcl}\n\\displaystyle\\min&\\frac{1}{2}\\mathbf{w}^T\\Sigma\\mathbf{w}\\\\\n\\textrm{s.t.}&\\mathbf{w}^{T}e&=&1\\\\\n&\\mu^{T}\\mathbf{w}&\\geq&M\\\\\n\\end{array}\n\\end{aligned}\n$$\n\nTo incorporate these conditions into one equation, introduce new variables $\\lambda_{i}$ that are the Lagrange multipliers and define a new function $\\mathcal{L}$ as follows:\n\n$$\n\\begin{aligned}\n\\mathcal{L}(\\mathbf{w},\\lambda)&=\\frac{1}{2}\\mathbf{w}^{T}\\Sigma\\mathbf{w}-\\lambda_{1}(\\mathbf{w}^{T}e-1)\n\\end{aligned}\n$$\n\nThen, to minimize this function, take derivatives with respect to $w$ and Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial w}&=\\mathbf{w}\\Sigma-\\lambda_{1}e=0\\\\\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial \\lambda_{1}}&=\\mathbf{w}e^T-1=0\n\\end{aligned}\n$$\n\nSimplify the equations above in matrix form and solve for the Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\begin{bmatrix}\n\\Sigma & e \\\\\ne^{T} & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n0 \\\\\n1\n\\end{bmatrix}\n\\\\\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n\\Sigma & e \\\\\ne^{T} & 0\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n0 \\\\\n1\n\\end{bmatrix}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntarget <- 0.03\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmin_var_optim <- function(mu, sigma, target) {\n    \n    params <- Variable(length(mu))\n    \n    obj <- Minimize(quad_form(params, sigma))\n    \n    cons <- list(sum(params) == 1, params >= 0,\n                 sum(mu * params) >= target)\n    \n    prob <- Problem(obj, cons)\n    \n    result <- solve(prob)$getValue(params)\n    \n    return(result)\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams2 <- t(min_var_optim(mu, sigma, target))\nparams2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]      [,2]      [,3]         [,4]\n[1,] 0.297739 0.4697464 0.2325146 1.854339e-21\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams2 %*% mu\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,] 0.03\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(params2 %*% sigma %*% t(params2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.03878172\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# roll_min_var(sigma)\n```\n:::\n\n\n## Maximize utility\n\n$$\n\\begin{aligned}\n\\begin{array}{rrcl}\n\\displaystyle\\min&\\frac{1}{2}\\delta(\\mathbf{w}^{T}\\Sigma\\mathbf{w})-\\mu^{T}\\mathbf{w}\\\\\n\\textrm{s.t.}&\\mathbf{w}^{T}e&=&1\\\\\n\\end{array}\n\\end{aligned}\n$$\n\nTo incorporate these conditions into one equation, introduce new variables $\\lambda_{i}$ that are the Lagrange multipliers and define a new function $\\mathcal{L}$ as follows:\n\n$$\n\\begin{aligned}\n\\mathcal{L}(\\mathbf{w},\\lambda)&=\\frac{1}{2}\\mathbf{w}^{T}\\Sigma\\mathbf{w}-\\mu^{T}\\mathbf{w}-\\lambda_{1}(\\mathbf{w}^{T}e-1)\n\\end{aligned}\n$$\n\nThen, to minimize this function, take derivatives with respect to $w$ and Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial w}&=\\mathbf{w}\\Sigma-\\mu^{T}-\\lambda_{1}e=0\\\\\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial \\lambda_{1}}&=\\mathbf{w}e^T-1=0\n\\end{aligned}\n$$\n\nSimplify the equations above in matrix form and solve for the Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\begin{bmatrix}\n\\Sigma & e \\\\\ne^{T} & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n\\mu^{T} \\\\\n1\n\\end{bmatrix}\n\\\\\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n\\Sigma & e \\\\\ne^{T} & 0\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n\\mu^{T} \\\\\n1\n\\end{bmatrix}\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nir <- 0.5\ntarget <- ir / 0.06 # ir / std (see Black-Litterman)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmax_utility_optim <- function(mu, sigma, target) {\n    \n    params <- Variable(length(mu))\n    \n    obj <- Minimize(0.5 * target * quad_form(params, sigma) - t(mu) %*% params)\n    \n    cons <- list(sum(params) == 1, params >= 0)\n    \n    prob <- Problem(obj, cons)\n        \n    result <- solve(prob)$getValue(params)\n    \n    return(result)\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams3 <- t(max_utility_optim(mu, sigma, target))\nparams3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]          [,3]          [,4]\n[1,] 0.5204303 0.4795697 -8.450996e-23 -3.213608e-23\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams3 %*% mu \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.04816717\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(params3 %*% sigma %*% t(params3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.06485876\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# roll_max_utility(mu, sigma)\n```\n:::\n\n\n## Minimize residual sum of squares\n\n$$\n\\begin{aligned}\n\\begin{array}{rrcl}\n\\displaystyle\\min&\\frac{1}{2}\\delta(\\mathbf{w}^{T}X^{T}X\\mathbf{w})-X^{T}y\\mathbf{w}\\\\\n\\textrm{s.t.}&\\mathbf{w}^{T}e&=&1\\\\\n\\end{array}\n\\end{aligned}\n$$\n\nTo incorporate these conditions into one equation, introduce new variables $\\lambda_{i}$ that are the Lagrange multipliers and define a new function $\\mathcal{L}$ as follows:\n\n$$\n\\begin{aligned}\n\\mathcal{L}(\\mathbf{w},\\lambda)&=\\frac{1}{2}\\mathbf{w}^{T}X^{T}X\\mathbf{w}-X^{T}y\\mathbf{w}-\\lambda_{1}(\\mathbf{w}^{T}e-1)\n\\end{aligned}\n$$\n\nThen, to minimize this function, take derivatives with respect to $w$ and Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial w}&=\\mathbf{w}X^{T}X-X^{T}y-\\lambda_{1}e=0\\\\\n\\frac{\\partial\\mathcal{L}(\\mathbf{w},\\lambda)}{\\partial \\lambda_{1}}&=\\mathbf{w}e^T-1=0\n\\end{aligned}\n$$\n\nSimplify the equations above in matrix form and solve for the Lagrange multipliers $\\lambda_{i}$:\n\n$$\n\\begin{aligned}\n\\begin{bmatrix}\nX^{T}X & e \\\\\ne^{T} & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\nX^{T}y \\\\\n1\n\\end{bmatrix}\n\\\\\n\\begin{bmatrix}\n\\mathbf{w} \\\\\n-\\lambda_{1}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\nX^{T}X & e \\\\\ne^{T} & 0\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\nX^{T}y \\\\\n1\n\\end{bmatrix}\n\\end{aligned}\n$$\n\n-   <https://scaron.info/blog/conversion-from-least-squares-to-quadratic-programming.html>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmin_rss_optim1 <- function(mu, sigma) {\n    \n    params <- Variable(length(mu))\n    \n    obj <- Minimize(0.5 * quad_form(params, sigma) - t(mu) %*% params)\n    \n    cons <- list(sum(params) == 1, params >= 0)\n    \n    prob <- Problem(obj, cons)\n        \n    result <- solve(prob)$getValue(params)\n    \n    return(result)\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams4 <- t(min_rss_optim1(crossprod(overlap_x_xts, overlap_y_xts), crossprod(overlap_x_xts)))\nparams4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]          [,2]     [,3]         [,4]\n[1,] 0.399036 -5.338732e-23 0.600964 3.776735e-23\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams4 %*% mu \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.03189173\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(params4 %*% sigma %*% t(params4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.05686321\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# roll_min_rss(xx, xy)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmin_rss_optim2 <- function(x, y) {\n    \n    params <- Variable(ncol(x))\n    \n    obj <- Minimize(sum_squares(y - x %*% params))\n    \n    cons <- list(sum(params) == 1, params >= 0)\n    \n    prob <- Problem(obj, cons)\n        \n    result <- solve(prob)$getValue(params)\n    \n    return(result)\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams5 <- t(min_rss_optim2(coredata(overlap_x_xts), coredata(overlap_y_xts)))\nparams5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]          [,2]     [,3]          [,4]\n[1,] 0.399036 -1.004458e-20 0.600964 -6.314016e-21\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams5 %*% mu \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.03189173\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(params5 %*% sigma %*% t(params5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] 0.05686321\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nround(data.frame(\"max_pnl\" = t(params1) * 100,\n                 \"min_risk\" = t(params2) * 100,\n                 \"max_ratio\" = t(params3) * 100,\n                 \"min_rss1\" = t(params4) * 100,\n                 \"min_rss2\" = t(params5) * 100), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  max_pnl min_risk max_ratio min_rss1 min_rss2\n1      48    29.77     52.04     39.9     39.9\n2      52    46.97     47.96      0.0      0.0\n3       0    23.25      0.00     60.1     60.1\n4       0     0.00      0.00      0.0      0.0\n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}