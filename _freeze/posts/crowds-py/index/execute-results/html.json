{
  "hash": "faa38512fffef248de364f5674577652",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Crowds\"\nauthor: \"[Jason Foster](mailto:jason.j.foster@gmail.com)\"\ndate: last-modified\ncategories:\n  - analysis\n  - finance\n  - python\ndraft: true\n---\n\n::: {.cell}\n\n```{.python .cell-code}\nfactors_r = [\"SP500\"] # \"SP500\" does not contain dividends\nfactors_d = [\"DTB3\"]\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n# Parse web\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport requests\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nclass Filter:\n  \n  @staticmethod\n  def process(filter):\n  \n    operator, operands = filter\n    \n    result = {\n      \"operator\": operator,\n      \"operands\": [\n          {\"operator\": operand[0], \"operands\": operand[1]} for operand in operands\n      ],\n    }\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nclass Query:\n  \n  @staticmethod\n  def create(filters = [(\"or\", [(\"eq\", [\"region\", \"us\"])])],\n             top_operator = \"and\"):\n    \n    result = {\n      \"operator\": top_operator,\n      \"operands\": [Filter.process(filter) for filter in filters],\n    }\n\n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nclass Payload:\n  \n  @staticmethod\n  def create(quote_type = \"equity\", query = Query.create(),\n             size = 25, offset = 0,\n             sort_field = None, sort_type = None,\n             top_operator = \"and\"):\n    \n    result = {\n      \"includeFields\": None,  # unable to modify the result\n      \"offset\": offset,\n      \"query\": query,\n      \"quoteType\": quote_type,\n      \"size\": size,\n      \"sortField\": sort_field,\n      \"sortType\": sort_type,\n      \"topOperator\": top_operator,\n    }\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nclass Session:\n  \n  @staticmethod\n  def get():\n    \n    session = requests.Session()\n    \n    api_url = \"https://query1.finance.yahoo.com/v1/test/getcrumb\"\n    \n    headers = {\n      \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n    }\n    \n    session.headers.update(headers)\n  \n    response = session.get(api_url)\n    \n    crumb = response.text.strip()\n    cookies = session.cookies.get_dict()\n  \n    result = {\n      \"handle\": session,\n      \"crumb\": crumb,\n      \"cookies\": cookies\n    }\n    \n    return result\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nclass Screen:\n  \n  # @staticmethod\n  # def encode(params):\n  #   \n  #   result = \"?\" + \"&\".join(f\"{key}={value}\" for key, value in params.items())\n  #   \n  #   return result\n  \n  @staticmethod\n  def get(payload = Payload.create()):\n  \n    session = Session.get()\n    crumb = session[\"crumb\"]\n    cookies = session[\"cookies\"]\n    handle = session[\"handle\"]\n  \n    params = {\n      \"crumb\": crumb,\n      \"lang\": \"en-US\",\n      \"region\": \"US\",\n      \"formatted\": \"true\",\n      \"corsDomain\": \"finance.yahoo.com\",\n    }\n  \n    api_url = \"https://query1.finance.yahoo.com/v1/finance/screener\" # + Screen.encode(params)\n  \n    headers = {\n      # \"Content-Type\": \"application/json\",\n      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n    }\n  \n    max_size = 250\n    size = payload[\"size\"]\n    offset = payload[\"offset\"]\n    \n    result_cols = set()\n    result_ls = []\n\n    while size > 0:\n  \n      chunk_size = min(size, max_size)\n      payload[\"size\"] = chunk_size\n      payload[\"offst\"] = offset\n  \n      for key, value in cookies.items():\n        handle.cookies.set(key, value)\n  \n      response = handle.post(api_url, params = params, json = payload, headers = headers)\n  \n      result = response.json()\n      result_df = result[\"finance\"][\"result\"][0][\"quotes\"]\n  \n      if (result_df is not None):\n        \n        result_df = pd.json_normalize(result_df)\n        \n        result_ls.append(result_df)\n        result_cols.update(result_df.columns)\n  \n        size -= chunk_size\n        offset += chunk_size\n  \n      else:\n        size = 0\n        \n    result_cols = list(result_cols)\n    \n    for i in range(len(result_ls)):\n      \n      x = result_ls[i]\n      cols_na = set(result_cols) - set(x.columns)\n      \n      for j in cols_na:\n        x[j] = None\n        \n      result_ls[i] = x[result_cols]\n    \n    result = pd.concat(result_ls, ignore_index = True)\n    \n    return result\n```\n:::\n\n\n# Optimization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport json\nimport cvxpy as cp\nimport yfinance as yf\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef min_rss_optim(x, y):\n    \n    w = cp.Variable(x.shape[1])\n    \n    objective = cp.Minimize(cp.sum_squares(y - x @ w))\n    \n    constraints = [cp.sum(w) == 1, w >= 0, w <= 1]\n    \n    problem = cp.Problem(objective, constraints)\n    problem.solve()\n    \n    return w.value\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfilters = [(\"or\", [(\"eq\", [\"categoryname\", \"Tactical Allocation\"])])]\nquery = Query.create(filters)\npayload = Payload.create(quote_type = \"mutualfund\", query = query, size = 250,\n                         sort_field = \"fundnetassets\")\nscreen = Screen.get(payload)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nsorted_df = screen.sort_values(by = [\"netAssets.raw\", \"firstTradeDateMilliseconds\"])\ntickers = sorted_df.loc[~sorted_df[\"netAssets.raw\"].duplicated(), \"symbol\"].tolist()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# allocations = [\"AOK\", \"AOM\", \"AOR\", \"AOA\"]\n# tickers = tickers + allocations\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndef pnl(x):\n    return np.nanprod(1 + x) - 1\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nperformance_df = returns_df[\"returns\"].rolling(width, min_periods = 1).apply(pnl, raw = False)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nn_rows = overlap_df.shape[0]\nresult_ls = []\nindex_ls = []\n\n# for i in range(width - 1, n_rows):\nfor i in range(n_rows - 1, n_rows):\n  \n  idx = range(max(i - width + 1, 0), i + 1)\n  x_subset = overlap_x_df.iloc[idx]\n  y_subset = overlap_y_df.iloc[idx]\n  params_ls = []\n  tickers_ls = []\n  performance_ls = []\n  \n  # for j in [ticker for ticker in tickers if ticker not in allocations]:\n  for j in tickers:\n    \n    idx = ~x_subset.isna().any(axis = 1) & ~y_subset[j].isna()\n    x_complete = x_subset.loc[idx]\n    y_complete = y_subset.loc[idx, j]\n    \n    if (x_complete.shape[0] > 0) and (y_complete.size > 0):\n        \n      params = min_rss_optim(x_complete.values, y_complete.values)\n      params_ls.append(params)\n      \n      tickers_ls.append(j)\n      \n      performance_ls.append(performance_df[j].iloc[i])\n\n  if params_ls:\n    \n    result = pd.DataFrame(params_ls, index = tickers_ls)\n    result[\"performance\"] = performance_ls\n    \n    result_ls.append(result)\n    index_ls.append(overlap_x_df.index[i])\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# json.dump([x.to_dict() for x in result_ls], open(\"result_ls.json\", \"w\"))\n# json.dump([x.isoformat() for x in index_ls], open(\"index_ls.json\", \"w\"))\n```\n:::\n\n\n# Performance\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# result_ls = [pd.DataFrame(x) for x in json.load(open(\"result_ls.json\", \"r\"))]\n# index_ls = [pd.Timestamp(x) for x in json.load(open(\"index_ls.json\", \"r\"))]\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}